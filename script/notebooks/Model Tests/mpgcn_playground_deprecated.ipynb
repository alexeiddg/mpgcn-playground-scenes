{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MPGCN Playground Pipeline (Deprecated)",
   "id": "f0adf2c917914997"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is the intial test pipeline, it has since then been simplified and no longer works as the change in the split strategy to folds supports the new pipeline. For the correct training pipeline refer to /mpgcn_playground.ipynb",
   "id": "70859daaaf206340"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:23.975146Z",
     "start_time": "2025-11-26T18:28:23.109569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from src.reader import Playground_Reader\n",
    "from src.dataset import create as create_dataset\n",
    "from src.model.MPGCN import MPGCN\n",
    "\n",
    "def to_ns(d):\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: to_ns(v) for k, v in d.items()})\n",
    "    elif isinstance(d, list):\n",
    "        return [to_ns(x) for x in d]\n",
    "    return d\n",
    "\n",
    "def resolve_path(path: str):\n",
    "    if path.startswith(\"./\"):\n",
    "        base = os.path.abspath(\".\")\n",
    "        return os.path.join(base, path[2:])\n",
    "    return path"
   ],
   "id": "be0e90f9572190a8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:34.821425Z",
     "start_time": "2025-11-26T18:28:25.624395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gendata_yaml_path = \"./config/playground_gendata.yaml\"\n",
    "with open(gendata_yaml_path, \"r\") as f:\n",
    "    gendata_cfg = yaml.safe_load(f)\n",
    "\n",
    "dataset_args = gendata_cfg[\"dataset_args\"]\n",
    "\n",
    "dataset_args[\"dataset_root_folder\"] = resolve_path(dataset_args[\"dataset_root_folder\"])\n",
    "dataset_args[\"out_folder\"] = resolve_path(dataset_args[\"out_folder\"])\n",
    "\n",
    "print(\"Root folder resolved →\", dataset_args[\"dataset_root_folder\"])\n",
    "print(\"Output folder resolved →\", dataset_args[\"out_folder\"])\n",
    "\n",
    "reader = Playground_Reader(\n",
    "    dataset_root_folder = dataset_args[\"dataset_root_folder\"],\n",
    "    out_folder = dataset_args[\"out_folder\"],\n",
    "    label_csv_path = \"./data/processed/mpgcn_labels.csv\",\n",
    "    num_frame = dataset_args[\"num_frame\"],\n",
    ")\n",
    "\n",
    "reader.start()"
   ],
   "id": "4460f3a8d90db428",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PART 1: DATA GENERATION ===\n",
      "Loaded gendata YAML config.\n",
      "Root folder resolved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "Output folder resolved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir\n",
      "Starting data generation...\n",
      "Starting dataset build from CSV with repeated stratified K-folds...\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 00 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 5306.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 1885.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 00 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_00\n",
      "Unique object shapes found for fold 00 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_00\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 01 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22542.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4933.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 01 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_01\n",
      "Unique object shapes found for fold 01 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_01\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 02 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22248.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5004.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 02 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_02\n",
      "Unique object shapes found for fold 02 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_02\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 03 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22396.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4796.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 03 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_03\n",
      "Unique object shapes found for fold 03 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_03\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 04 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 18871.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 3574.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 04 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_04\n",
      "Unique object shapes found for fold 04 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_04\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 05 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 19352.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 3303.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 05 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_05\n",
      "Unique object shapes found for fold 05 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_05\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 06 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 6704.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 2482.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 06 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_06\n",
      "Unique object shapes found for fold 06 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_06\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 07 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 12324.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4696.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 07 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_07\n",
      "Unique object shapes found for fold 07 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_07\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 08 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23089.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4739.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 08 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_08\n",
      "Unique object shapes found for fold 08 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_08\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 09 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 21977.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4240.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 09 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_09\n",
      "Unique object shapes found for fold 09 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_09\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 10 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22696.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4800.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 10 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_10\n",
      "Unique object shapes found for fold 10 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_10\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 11 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23173.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4990.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 11 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_11\n",
      "Unique object shapes found for fold 11 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_11\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 12 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23225.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4925.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 12 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_12\n",
      "Unique object shapes found for fold 12 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_12\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 13 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22816.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4870.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 13 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_13\n",
      "Unique object shapes found for fold 13 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_13\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 14 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23043.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5072.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 14 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_14\n",
      "Unique object shapes found for fold 14 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_14\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 15 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23057.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4013.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 15 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_15\n",
      "Unique object shapes found for fold 15 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_15\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 16 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23614.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5113.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 16 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_16\n",
      "Unique object shapes found for fold 16 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_16\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 17 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23427.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5140.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 17 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_17\n",
      "Unique object shapes found for fold 17 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_17\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 18 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23029.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4944.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 18 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_18\n",
      "Unique object shapes found for fold 18 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_18\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 19 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23052.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4989.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 19 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_19\n",
      "Unique object shapes found for fold 19 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_19\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 20 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22675.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4834.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 20 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_20\n",
      "Unique object shapes found for fold 20 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_20\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 21 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 20800.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4892.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 21 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_21\n",
      "Unique object shapes found for fold 21 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_21\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 22 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22139.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4835.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 22 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_22\n",
      "Unique object shapes found for fold 22 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_22\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 23 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22816.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4879.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 23 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_23\n",
      "Unique object shapes found for fold 23 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_23\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 24 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22309.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4854.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 24 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_24\n",
      "Unique object shapes found for fold 24 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_24\n",
      "Saved fold class distribution summary → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_summary_actual.json\n",
      "Data generation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:42.245744Z",
     "start_time": "2025-11-26T18:28:42.239817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mpgcn_yaml_path = \"./config/playground/mpgcn.yaml\"\n",
    "with open(mpgcn_yaml_path, \"r\") as f:\n",
    "    mpgcn_cfg = yaml.safe_load(f)\n",
    "\n",
    "args = to_ns(mpgcn_cfg)\n",
    "args.config_path = mpgcn_yaml_path\n",
    "print(\"Loaded MPGCN YAML config.\")\n",
    "\n",
    "args.work_dir = \"./workdir\"\n",
    "args.dataset_args.root_folder = \"./workdir\"\n",
    "args.dataset_args.object_folder = \"./workdir\"\n",
    "\n",
    "print(\"Root folder:\", args.dataset_args.root_folder)"
   ],
   "id": "299ef8b6673364af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PART 2: MODEL TRAINING ===\n",
      "Loaded MPGCN YAML config.\n",
      "Root folder: ./workdir\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:43.988289Z",
     "start_time": "2025-11-26T18:28:43.983948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "train_labels_path = os.path.join(args.dataset_args.root_folder, \"train_label.pkl\")\n",
    "\n",
    "with open(train_labels_path, \"rb\") as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "labels_arr = np.array([l for l, _ in train_labels])\n",
    "observed_classes = int(labels_arr.max()) + 1\n",
    "\n",
    "print(\"Observed label classes:\", observed_classes)"
   ],
   "id": "3c73b879f106353e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed label classes: 3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:45.320887Z",
     "start_time": "2025-11-26T18:28:45.318385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args.dataset_args.debug = False\n",
    "args.dataset_args.augment = True\n",
    "\n",
    "args.model_args.num_class = observed_classes\n",
    "\n",
    "print(\"Model will be built with num_class =\", args.model_args.num_class)"
   ],
   "id": "b6ed83a7464cb0fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be built with num_class = 3\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:47.124214Z",
     "start_time": "2025-11-26T18:28:47.106011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create dataset\n",
    "feeders, data_shape, num_class, A, parts = create_dataset(\n",
    "    args.dataset,\n",
    "    **vars(args.dataset_args)\n",
    ")\n",
    "\n",
    "print(\"train samples:\", len(feeders[\"train\"]))\n",
    "print(\"eval samples :\", len(feeders[\"eval\"]))\n",
    "print(\"data shape   :\", data_shape)\n",
    "print(\"num classes  :\", num_class)"
   ],
   "id": "928456c90d4a6dc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 905\n",
      "eval samples : 181\n",
      "data shape   : [4, 6, 48, 84, 1]\n",
      "num classes  : 3\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:48.737215Z",
     "start_time": "2025-11-26T18:28:48.599193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert adjacency matrix\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "A_tensor = A_tensor.to(device)\n",
    "\n",
    "# Build the model with ALL required arguments\n",
    "model = MPGCN(\n",
    "    data_shape=data_shape,     # shape: [4, 6, 48, 96, 1]\n",
    "    A=A_tensor,                # adjacency, now torch.Tensor\n",
    "    parts=parts,               # <-- REQUIRED\n",
    "    num_class=args.model_args.num_class,\n",
    "    use_att=args.model_args.use_att,\n",
    "    kernel_size=args.model_args.kernel_size,\n",
    "    dilation=args.model_args.dilation,\n",
    "    reduct_ratio=args.model_args.reduct_ratio\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model successfully built!\")"
   ],
   "id": "a881018db6a8c5cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model successfully built!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:51.515463Z",
     "start_time": "2025-11-26T18:28:51.508597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample, label, clip = feeders[\"train\"][0]\n",
    "\n",
    "x = torch.tensor(sample).float().unsqueeze(0)  # add batch dim\n",
    "y = torch.tensor([label])\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "print(\"Input tensor:\", x.shape)\n",
    "print(\"Label:\", y)"
   ],
   "id": "6160d8701504e20e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor: torch.Size([1, 4, 6, 48, 84, 1])\n",
      "Label: tensor([1])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:53.346519Z",
     "start_time": "2025-11-26T18:28:53.250413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_tuple = model(x)\n",
    "logits = out_tuple[0]   # MP-GCN returns (output, feature_maps)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ],
   "id": "b54c93895e17bc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 3])\n",
      "Logits: tensor([[0.0292, 0.0196, 0.0022]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:28:55.506Z",
     "start_time": "2025-11-26T18:28:54.970898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.9,\n",
    "    nesterov=True,\n",
    "    weight_decay=0.0002\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "f1b6582d11f9b5fa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:29:00.705646Z",
     "start_time": "2025-11-26T18:28:59.773164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data loaders for batch training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = args.dataset_args.train_batch_size\n",
    "eval_batch_size = args.dataset_args.eval_batch_size\n",
    "\n",
    "# Create weighted sampler for balanced training\n",
    "train_labels = []\n",
    "for _, y, _ in feeders['train']:\n",
    "    train_labels.append(int(y))\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "class_counts = np.bincount(train_labels, minlength=observed_classes) + 1e-6\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = class_weights[train_labels]\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    feeders['train'],\n",
    "    batch_size=train_batch_size, \n",
    "    sampler=train_sampler,\n",
    "    num_workers=4 if torch.cuda.is_available() else 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    feeders['eval'],\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4 if torch.cuda.is_available() else 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"Created data loaders with train_batch_size={train_batch_size}, eval_batch_size={eval_batch_size}\")\n",
    "print(f\"Train samples: {len(feeders['train'])}, batches: {len(train_loader)}\")\n",
    "print(f\"Eval samples: {len(feeders['eval'])}, batches: {len(eval_loader)}\")"
   ],
   "id": "d677776b4a1e0a9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data loaders with train_batch_size=8, eval_batch_size=8\n",
      "Train samples: 905, batches: 113\n",
      "Eval samples: 181, batches: 23\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T18:29:05.821396Z",
     "start_time": "2025-11-26T18:29:05.815980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from src.scheduler import create as create_scheduler\n",
    "\n",
    "# scheduler_args is a SimpleNamespace, so get attribute dynamically\n",
    "scheduler_args = getattr(args.scheduler_args, args.lr_scheduler)\n",
    "scheduler_args_dict = vars(scheduler_args)\n",
    "\n",
    "max_epoch = scheduler_args_dict[\"max_epoch\"]\n",
    "warm_up = scheduler_args_dict[\"warm_up\"]\n",
    "\n",
    "print(f\"Using {args.lr_scheduler} scheduler with max_epoch={max_epoch}, warm_up={warm_up}\")\n",
    "\n",
    "# Create the scheduler\n",
    "lr_scheduler = create_scheduler(\n",
    "    args.lr_scheduler,\n",
    "    len(train_loader),\n",
    "    **scheduler_args_dict\n",
    ")\n",
    "\n",
    "eval_interval, lr_lambda = lr_scheduler.get_lambda()\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ],
   "id": "5904634bd2a0d016",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine scheduler with max_epoch=65, warm_up=5\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T21:22:39.797833Z",
     "start_time": "2025-11-25T19:14:12.323387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Full training loop with validation\n",
    "print(\"Starting full model training...\")\n",
    "\n",
    "# Track best model and metrics\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "global_step = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(max_epoch):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{max_epoch}\")\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        data = data.float().to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "        global_step += 1\n",
    "\n",
    "        # Print progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f} | \"\n",
    "                  f\"Acc: {100.*correct/total:.2f}% ({correct}/{total}) | \"\n",
    "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Print epoch results\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    # Validation phase (every eval_interval epochs)\n",
    "    if (epoch+1) % eval_interval(epoch) == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        print(\"Evaluating...\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target, _) in enumerate(eval_loader):\n",
    "                # Move data to device\n",
    "                data = data.float().to(device)\n",
    "                target = target.long().to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output, _ = model(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "\n",
    "        # Print validation results\n",
    "        val_loss /= len(eval_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            print(f\"New best model with accuracy: {best_acc:.2f}%\")\n",
    "            # Save model checkpoint (optional)\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch + 1,\n",
    "            #     'model_state_dict': model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #     'scheduler_state_dict': scheduler.state_dict(),\n",
    "            #     'best_acc': best_acc,\n",
    "            # }, f'./workdir/best_model.pth')\n",
    "\n",
    "print(f\"Training completed. Best accuracy: {best_acc:.2f}% at epoch {best_epoch}\")"
   ],
   "id": "594c879b24b9cd8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full model training...\n",
      "\n",
      "Epoch 1/65\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexeidelgado/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/113 | Loss: 1.1053 | Acc: 25.00% (2/8) | LR: 0.000088\n",
      "Batch 10/113 | Loss: 1.2136 | Acc: 36.36% (32/88) | LR: 0.000973\n",
      "Batch 20/113 | Loss: 0.6334 | Acc: 39.29% (66/168) | LR: 0.001858\n",
      "Batch 30/113 | Loss: 0.8112 | Acc: 42.74% (106/248) | LR: 0.002743\n",
      "Batch 40/113 | Loss: 1.1927 | Acc: 42.07% (138/328) | LR: 0.003628\n",
      "Batch 50/113 | Loss: 1.9324 | Acc: 41.91% (171/408) | LR: 0.004513\n",
      "Batch 60/113 | Loss: 0.9392 | Acc: 40.37% (197/488) | LR: 0.005398\n",
      "Batch 70/113 | Loss: 3.9049 | Acc: 39.08% (222/568) | LR: 0.006283\n",
      "Batch 80/113 | Loss: 1.3919 | Acc: 39.97% (259/648) | LR: 0.007168\n",
      "Batch 90/113 | Loss: 1.0864 | Acc: 39.42% (287/728) | LR: 0.008053\n",
      "Batch 100/113 | Loss: 3.1084 | Acc: 39.73% (321/808) | LR: 0.008938\n",
      "Batch 110/113 | Loss: 1.8690 | Acc: 39.64% (352/888) | LR: 0.009823\n",
      "Train Loss: 1.5211 | Train Acc: 39.71%\n",
      "\n",
      "Epoch 2/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 3.0057 | Acc: 25.00% (2/8) | LR: 0.010088\n",
      "Batch 10/113 | Loss: 2.2983 | Acc: 40.91% (36/88) | LR: 0.010973\n",
      "Batch 20/113 | Loss: 1.6783 | Acc: 40.48% (68/168) | LR: 0.011858\n",
      "Batch 30/113 | Loss: 1.8310 | Acc: 37.50% (93/248) | LR: 0.012743\n",
      "Batch 40/113 | Loss: 2.0654 | Acc: 39.33% (129/328) | LR: 0.013628\n",
      "Batch 50/113 | Loss: 1.8170 | Acc: 40.44% (165/408) | LR: 0.014513\n",
      "Batch 60/113 | Loss: 1.8410 | Acc: 41.19% (201/488) | LR: 0.015398\n",
      "Batch 70/113 | Loss: 1.0298 | Acc: 39.79% (226/568) | LR: 0.016283\n",
      "Batch 80/113 | Loss: 0.9873 | Acc: 41.05% (266/648) | LR: 0.017168\n",
      "Batch 90/113 | Loss: 1.3803 | Acc: 40.93% (298/728) | LR: 0.018053\n",
      "Batch 100/113 | Loss: 0.9916 | Acc: 41.09% (332/808) | LR: 0.018938\n",
      "Batch 110/113 | Loss: 1.8734 | Acc: 39.98% (355/888) | LR: 0.019823\n",
      "Train Loss: 1.6216 | Train Acc: 40.49%\n",
      "\n",
      "Epoch 3/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.5862 | Acc: 0.00% (0/8) | LR: 0.020088\n",
      "Batch 10/113 | Loss: 1.3614 | Acc: 29.55% (26/88) | LR: 0.020973\n",
      "Batch 20/113 | Loss: 0.6882 | Acc: 33.33% (56/168) | LR: 0.021858\n",
      "Batch 30/113 | Loss: 1.3067 | Acc: 33.87% (84/248) | LR: 0.022743\n",
      "Batch 40/113 | Loss: 0.8228 | Acc: 36.89% (121/328) | LR: 0.023628\n",
      "Batch 50/113 | Loss: 1.1693 | Acc: 36.76% (150/408) | LR: 0.024513\n",
      "Batch 60/113 | Loss: 0.9010 | Acc: 38.52% (188/488) | LR: 0.025398\n",
      "Batch 70/113 | Loss: 0.8036 | Acc: 38.03% (216/568) | LR: 0.026283\n",
      "Batch 80/113 | Loss: 2.7235 | Acc: 37.50% (243/648) | LR: 0.027168\n",
      "Batch 90/113 | Loss: 1.2042 | Acc: 36.81% (268/728) | LR: 0.028053\n",
      "Batch 100/113 | Loss: 1.3071 | Acc: 37.25% (301/808) | LR: 0.028938\n",
      "Batch 110/113 | Loss: 0.9154 | Acc: 37.73% (335/888) | LR: 0.029823\n",
      "Train Loss: 1.2571 | Train Acc: 37.83%\n",
      "\n",
      "Epoch 4/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.3599 | Acc: 25.00% (2/8) | LR: 0.030088\n",
      "Batch 10/113 | Loss: 1.0019 | Acc: 37.50% (33/88) | LR: 0.030973\n",
      "Batch 20/113 | Loss: 1.2808 | Acc: 39.88% (67/168) | LR: 0.031858\n",
      "Batch 30/113 | Loss: 0.9102 | Acc: 38.71% (96/248) | LR: 0.032743\n",
      "Batch 40/113 | Loss: 1.1734 | Acc: 38.72% (127/328) | LR: 0.033628\n",
      "Batch 50/113 | Loss: 1.7159 | Acc: 37.25% (152/408) | LR: 0.034513\n",
      "Batch 60/113 | Loss: 1.0085 | Acc: 37.50% (183/488) | LR: 0.035398\n",
      "Batch 70/113 | Loss: 1.1422 | Acc: 38.73% (220/568) | LR: 0.036283\n",
      "Batch 80/113 | Loss: 1.3160 | Acc: 39.35% (255/648) | LR: 0.037168\n",
      "Batch 90/113 | Loss: 1.1633 | Acc: 38.46% (280/728) | LR: 0.038053\n",
      "Batch 100/113 | Loss: 0.7245 | Acc: 38.74% (313/808) | LR: 0.038938\n",
      "Batch 110/113 | Loss: 1.4338 | Acc: 38.85% (345/888) | LR: 0.039823\n",
      "Train Loss: 1.2107 | Train Acc: 38.94%\n",
      "\n",
      "Epoch 5/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9758 | Acc: 62.50% (5/8) | LR: 0.040088\n",
      "Batch 10/113 | Loss: 0.9683 | Acc: 44.32% (39/88) | LR: 0.040973\n",
      "Batch 20/113 | Loss: 1.2475 | Acc: 42.26% (71/168) | LR: 0.041858\n",
      "Batch 30/113 | Loss: 0.8425 | Acc: 43.15% (107/248) | LR: 0.042743\n",
      "Batch 40/113 | Loss: 1.0672 | Acc: 41.46% (136/328) | LR: 0.043628\n",
      "Batch 50/113 | Loss: 1.0361 | Acc: 41.91% (171/408) | LR: 0.044513\n",
      "Batch 60/113 | Loss: 1.4699 | Acc: 41.60% (203/488) | LR: 0.045398\n",
      "Batch 70/113 | Loss: 1.2427 | Acc: 41.20% (234/568) | LR: 0.046283\n",
      "Batch 80/113 | Loss: 1.3501 | Acc: 42.13% (273/648) | LR: 0.047168\n",
      "Batch 90/113 | Loss: 0.9584 | Acc: 41.76% (304/728) | LR: 0.048053\n",
      "Batch 100/113 | Loss: 0.9268 | Acc: 42.70% (345/808) | LR: 0.048938\n",
      "Batch 110/113 | Loss: 1.2110 | Acc: 42.23% (375/888) | LR: 0.049823\n",
      "Train Loss: 1.1683 | Train Acc: 42.15%\n",
      "Evaluating...\n",
      "Val Loss: 2.1264 | Val Acc: 46.41%\n",
      "New best model with accuracy: 46.41%\n",
      "\n",
      "Epoch 6/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9635 | Acc: 37.50% (3/8) | LR: 0.050000\n",
      "Batch 10/113 | Loss: 1.1507 | Acc: 45.45% (40/88) | LR: 0.050000\n",
      "Batch 20/113 | Loss: 1.3344 | Acc: 47.62% (80/168) | LR: 0.049999\n",
      "Batch 30/113 | Loss: 1.2226 | Acc: 41.53% (103/248) | LR: 0.049997\n",
      "Batch 40/113 | Loss: 1.2387 | Acc: 41.77% (137/328) | LR: 0.049995\n",
      "Batch 50/113 | Loss: 1.4562 | Acc: 42.40% (173/408) | LR: 0.049993\n",
      "Batch 60/113 | Loss: 1.3540 | Acc: 43.85% (214/488) | LR: 0.049990\n",
      "Batch 70/113 | Loss: 0.8566 | Acc: 43.49% (247/568) | LR: 0.049986\n",
      "Batch 80/113 | Loss: 2.0568 | Acc: 44.14% (286/648) | LR: 0.049982\n",
      "Batch 90/113 | Loss: 1.3441 | Acc: 43.68% (318/728) | LR: 0.049978\n",
      "Batch 100/113 | Loss: 1.4211 | Acc: 43.32% (350/808) | LR: 0.049973\n",
      "Batch 110/113 | Loss: 1.0131 | Acc: 43.24% (384/888) | LR: 0.049967\n",
      "Train Loss: 1.1286 | Train Acc: 43.25%\n",
      "\n",
      "Epoch 7/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9728 | Acc: 50.00% (4/8) | LR: 0.049965\n",
      "Batch 10/113 | Loss: 0.8551 | Acc: 50.00% (44/88) | LR: 0.049959\n",
      "Batch 20/113 | Loss: 0.9316 | Acc: 49.40% (83/168) | LR: 0.049952\n",
      "Batch 30/113 | Loss: 0.8177 | Acc: 48.79% (121/248) | LR: 0.049944\n",
      "Batch 40/113 | Loss: 0.9090 | Acc: 45.12% (148/328) | LR: 0.049936\n",
      "Batch 50/113 | Loss: 1.4429 | Acc: 43.63% (178/408) | LR: 0.049928\n",
      "Batch 60/113 | Loss: 0.9562 | Acc: 43.44% (212/488) | LR: 0.049919\n",
      "Batch 70/113 | Loss: 1.1885 | Acc: 44.19% (251/568) | LR: 0.049909\n",
      "Batch 80/113 | Loss: 1.2414 | Acc: 43.98% (285/648) | LR: 0.049899\n",
      "Batch 90/113 | Loss: 0.9049 | Acc: 43.96% (320/728) | LR: 0.049888\n",
      "Batch 100/113 | Loss: 0.7859 | Acc: 44.68% (361/808) | LR: 0.049877\n",
      "Batch 110/113 | Loss: 1.0026 | Acc: 44.93% (399/888) | LR: 0.049865\n",
      "Train Loss: 1.0993 | Train Acc: 45.02%\n",
      "\n",
      "Epoch 8/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.2740 | Acc: 12.50% (1/8) | LR: 0.049862\n",
      "Batch 10/113 | Loss: 1.1349 | Acc: 40.91% (36/88) | LR: 0.049849\n",
      "Batch 20/113 | Loss: 0.9310 | Acc: 45.24% (76/168) | LR: 0.049836\n",
      "Batch 30/113 | Loss: 0.8207 | Acc: 43.95% (109/248) | LR: 0.049823\n",
      "Batch 40/113 | Loss: 1.2981 | Acc: 43.29% (142/328) | LR: 0.049809\n",
      "Batch 50/113 | Loss: 1.1136 | Acc: 43.38% (177/408) | LR: 0.049794\n",
      "Batch 60/113 | Loss: 0.9578 | Acc: 44.06% (215/488) | LR: 0.049779\n",
      "Batch 70/113 | Loss: 1.0014 | Acc: 45.42% (258/568) | LR: 0.049764\n",
      "Batch 80/113 | Loss: 1.0765 | Acc: 45.37% (294/648) | LR: 0.049747\n",
      "Batch 90/113 | Loss: 0.6881 | Acc: 45.74% (333/728) | LR: 0.049731\n",
      "Batch 100/113 | Loss: 0.9176 | Acc: 45.42% (367/808) | LR: 0.049714\n",
      "Batch 110/113 | Loss: 0.7017 | Acc: 46.06% (409/888) | LR: 0.049696\n",
      "Train Loss: 1.0931 | Train Acc: 45.80%\n",
      "\n",
      "Epoch 9/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9866 | Acc: 62.50% (5/8) | LR: 0.049690\n",
      "Batch 10/113 | Loss: 0.9003 | Acc: 45.45% (40/88) | LR: 0.049672\n",
      "Batch 20/113 | Loss: 0.9746 | Acc: 42.26% (71/168) | LR: 0.049653\n",
      "Batch 30/113 | Loss: 0.9894 | Acc: 44.76% (111/248) | LR: 0.049633\n",
      "Batch 40/113 | Loss: 1.1083 | Acc: 46.04% (151/328) | LR: 0.049613\n",
      "Batch 50/113 | Loss: 1.2149 | Acc: 44.61% (182/408) | LR: 0.049593\n",
      "Batch 60/113 | Loss: 1.1951 | Acc: 43.85% (214/488) | LR: 0.049572\n",
      "Batch 70/113 | Loss: 1.1483 | Acc: 45.07% (256/568) | LR: 0.049550\n",
      "Batch 80/113 | Loss: 0.8888 | Acc: 44.44% (288/648) | LR: 0.049528\n",
      "Batch 90/113 | Loss: 0.8084 | Acc: 45.88% (334/728) | LR: 0.049505\n",
      "Batch 100/113 | Loss: 0.8099 | Acc: 46.66% (377/808) | LR: 0.049482\n",
      "Batch 110/113 | Loss: 0.8178 | Acc: 46.17% (410/888) | LR: 0.049458\n",
      "Train Loss: 1.0366 | Train Acc: 45.91%\n",
      "\n",
      "Epoch 10/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9371 | Acc: 50.00% (4/8) | LR: 0.049451\n",
      "Batch 10/113 | Loss: 0.8969 | Acc: 55.68% (49/88) | LR: 0.049427\n",
      "Batch 20/113 | Loss: 1.0544 | Acc: 51.79% (87/168) | LR: 0.049402\n",
      "Batch 30/113 | Loss: 0.9071 | Acc: 49.19% (122/248) | LR: 0.049377\n",
      "Batch 40/113 | Loss: 0.8743 | Acc: 48.48% (159/328) | LR: 0.049351\n",
      "Batch 50/113 | Loss: 1.0426 | Acc: 48.04% (196/408) | LR: 0.049324\n",
      "Batch 60/113 | Loss: 0.9326 | Acc: 46.31% (226/488) | LR: 0.049297\n",
      "Batch 70/113 | Loss: 1.0747 | Acc: 47.01% (267/568) | LR: 0.049269\n",
      "Batch 80/113 | Loss: 1.0197 | Acc: 46.91% (304/648) | LR: 0.049241\n",
      "Batch 90/113 | Loss: 0.9481 | Acc: 47.25% (344/728) | LR: 0.049213\n",
      "Batch 100/113 | Loss: 1.2398 | Acc: 47.52% (384/808) | LR: 0.049184\n",
      "Batch 110/113 | Loss: 1.1850 | Acc: 47.86% (425/888) | LR: 0.049154\n",
      "Train Loss: 1.0570 | Train Acc: 48.01%\n",
      "Evaluating...\n",
      "Val Loss: 0.9849 | Val Acc: 57.46%\n",
      "New best model with accuracy: 57.46%\n",
      "\n",
      "Epoch 11/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7409 | Acc: 75.00% (6/8) | LR: 0.049145\n",
      "Batch 10/113 | Loss: 1.0916 | Acc: 61.36% (54/88) | LR: 0.049115\n",
      "Batch 20/113 | Loss: 1.4108 | Acc: 52.98% (89/168) | LR: 0.049084\n",
      "Batch 30/113 | Loss: 1.3641 | Acc: 50.40% (125/248) | LR: 0.049053\n",
      "Batch 40/113 | Loss: 1.0391 | Acc: 51.52% (169/328) | LR: 0.049021\n",
      "Batch 50/113 | Loss: 0.8541 | Acc: 52.21% (213/408) | LR: 0.048989\n",
      "Batch 60/113 | Loss: 1.1317 | Acc: 51.02% (249/488) | LR: 0.048956\n",
      "Batch 70/113 | Loss: 1.0848 | Acc: 50.00% (284/568) | LR: 0.048922\n",
      "Batch 80/113 | Loss: 1.4428 | Acc: 50.31% (326/648) | LR: 0.048888\n",
      "Batch 90/113 | Loss: 1.0165 | Acc: 50.41% (367/728) | LR: 0.048854\n",
      "Batch 100/113 | Loss: 1.2635 | Acc: 49.01% (396/808) | LR: 0.048819\n",
      "Batch 110/113 | Loss: 0.8066 | Acc: 48.87% (434/888) | LR: 0.048784\n",
      "Train Loss: 1.0312 | Train Acc: 48.78%\n",
      "\n",
      "Epoch 12/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0740 | Acc: 37.50% (3/8) | LR: 0.048773\n",
      "Batch 10/113 | Loss: 1.2058 | Acc: 37.50% (33/88) | LR: 0.048737\n",
      "Batch 20/113 | Loss: 0.8997 | Acc: 35.71% (60/168) | LR: 0.048700\n",
      "Batch 30/113 | Loss: 1.2828 | Acc: 40.32% (100/248) | LR: 0.048663\n",
      "Batch 40/113 | Loss: 1.0939 | Acc: 42.38% (139/328) | LR: 0.048625\n",
      "Batch 50/113 | Loss: 1.1253 | Acc: 43.14% (176/408) | LR: 0.048587\n",
      "Batch 60/113 | Loss: 1.3490 | Acc: 44.26% (216/488) | LR: 0.048549\n",
      "Batch 70/113 | Loss: 1.0633 | Acc: 46.30% (263/568) | LR: 0.048509\n",
      "Batch 80/113 | Loss: 0.7866 | Acc: 46.91% (304/648) | LR: 0.048470\n",
      "Batch 90/113 | Loss: 1.0772 | Acc: 47.53% (346/728) | LR: 0.048430\n",
      "Batch 100/113 | Loss: 0.9007 | Acc: 48.14% (389/808) | LR: 0.048389\n",
      "Batch 110/113 | Loss: 0.7864 | Acc: 48.42% (430/888) | LR: 0.048348\n",
      "Train Loss: 1.0272 | Train Acc: 48.12%\n",
      "\n",
      "Epoch 13/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.4136 | Acc: 25.00% (2/8) | LR: 0.048335\n",
      "Batch 10/113 | Loss: 1.3235 | Acc: 46.59% (41/88) | LR: 0.048294\n",
      "Batch 20/113 | Loss: 1.0889 | Acc: 48.81% (82/168) | LR: 0.048251\n",
      "Batch 30/113 | Loss: 1.0807 | Acc: 45.56% (113/248) | LR: 0.048208\n",
      "Batch 40/113 | Loss: 1.3068 | Acc: 45.73% (150/328) | LR: 0.048165\n",
      "Batch 50/113 | Loss: 1.1668 | Acc: 46.57% (190/408) | LR: 0.048121\n",
      "Batch 60/113 | Loss: 1.0542 | Acc: 44.67% (218/488) | LR: 0.048077\n",
      "Batch 70/113 | Loss: 0.9859 | Acc: 44.72% (254/568) | LR: 0.048032\n",
      "Batch 80/113 | Loss: 1.0273 | Acc: 44.44% (288/648) | LR: 0.047987\n",
      "Batch 90/113 | Loss: 1.2407 | Acc: 45.33% (330/728) | LR: 0.047941\n",
      "Batch 100/113 | Loss: 0.9042 | Acc: 45.17% (365/808) | LR: 0.047895\n",
      "Batch 110/113 | Loss: 1.0330 | Acc: 45.27% (402/888) | LR: 0.047848\n",
      "Train Loss: 1.0519 | Train Acc: 45.69%\n",
      "\n",
      "Epoch 14/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1813 | Acc: 12.50% (1/8) | LR: 0.047834\n",
      "Batch 10/113 | Loss: 0.9656 | Acc: 45.45% (40/88) | LR: 0.047787\n",
      "Batch 20/113 | Loss: 0.8233 | Acc: 45.83% (77/168) | LR: 0.047739\n",
      "Batch 30/113 | Loss: 0.6724 | Acc: 45.97% (114/248) | LR: 0.047690\n",
      "Batch 40/113 | Loss: 1.2460 | Acc: 46.34% (152/328) | LR: 0.047641\n",
      "Batch 50/113 | Loss: 0.9746 | Acc: 47.79% (195/408) | LR: 0.047592\n",
      "Batch 60/113 | Loss: 1.0813 | Acc: 48.77% (238/488) | LR: 0.047542\n",
      "Batch 70/113 | Loss: 1.1041 | Acc: 48.94% (278/568) | LR: 0.047492\n",
      "Batch 80/113 | Loss: 1.0083 | Acc: 48.77% (316/648) | LR: 0.047441\n",
      "Batch 90/113 | Loss: 0.9445 | Acc: 49.18% (358/728) | LR: 0.047390\n",
      "Batch 100/113 | Loss: 0.5431 | Acc: 49.38% (399/808) | LR: 0.047338\n",
      "Batch 110/113 | Loss: 0.8494 | Acc: 49.77% (442/888) | LR: 0.047286\n",
      "Train Loss: 0.9973 | Train Acc: 49.67%\n",
      "\n",
      "Epoch 15/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1631 | Acc: 25.00% (2/8) | LR: 0.047270\n",
      "Batch 10/113 | Loss: 1.0584 | Acc: 46.59% (41/88) | LR: 0.047217\n",
      "Batch 20/113 | Loss: 1.2932 | Acc: 50.60% (85/168) | LR: 0.047164\n",
      "Batch 30/113 | Loss: 0.8375 | Acc: 52.02% (129/248) | LR: 0.047110\n",
      "Batch 40/113 | Loss: 0.5571 | Acc: 51.83% (170/328) | LR: 0.047056\n",
      "Batch 50/113 | Loss: 1.0548 | Acc: 51.96% (212/408) | LR: 0.047001\n",
      "Batch 60/113 | Loss: 1.0828 | Acc: 51.02% (249/488) | LR: 0.046946\n",
      "Batch 70/113 | Loss: 0.9217 | Acc: 51.41% (292/568) | LR: 0.046890\n",
      "Batch 80/113 | Loss: 0.6519 | Acc: 52.31% (339/648) | LR: 0.046834\n",
      "Batch 90/113 | Loss: 1.6626 | Acc: 52.34% (381/728) | LR: 0.046777\n",
      "Batch 100/113 | Loss: 0.9086 | Acc: 52.85% (427/808) | LR: 0.046720\n",
      "Batch 110/113 | Loss: 0.8972 | Acc: 52.59% (467/888) | LR: 0.046662\n",
      "Train Loss: 0.9814 | Train Acc: 52.88%\n",
      "Evaluating...\n",
      "Val Loss: 1.1460 | Val Acc: 55.80%\n",
      "\n",
      "Epoch 16/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1527 | Acc: 37.50% (3/8) | LR: 0.046645\n",
      "Batch 10/113 | Loss: 0.9769 | Acc: 54.55% (48/88) | LR: 0.046587\n",
      "Batch 20/113 | Loss: 0.9931 | Acc: 57.14% (96/168) | LR: 0.046528\n",
      "Batch 30/113 | Loss: 0.8305 | Acc: 57.26% (142/248) | LR: 0.046469\n",
      "Batch 40/113 | Loss: 1.4865 | Acc: 56.71% (186/328) | LR: 0.046409\n",
      "Batch 50/113 | Loss: 0.8379 | Acc: 54.66% (223/408) | LR: 0.046349\n",
      "Batch 60/113 | Loss: 0.6692 | Acc: 54.71% (267/488) | LR: 0.046289\n",
      "Batch 70/113 | Loss: 0.9990 | Acc: 52.82% (300/568) | LR: 0.046228\n",
      "Batch 80/113 | Loss: 0.7653 | Acc: 53.40% (346/648) | LR: 0.046166\n",
      "Batch 90/113 | Loss: 1.0018 | Acc: 53.16% (387/728) | LR: 0.046104\n",
      "Batch 100/113 | Loss: 1.0321 | Acc: 52.23% (422/808) | LR: 0.046042\n",
      "Batch 110/113 | Loss: 1.1494 | Acc: 52.59% (467/888) | LR: 0.045979\n",
      "Train Loss: 1.0011 | Train Acc: 52.77%\n",
      "\n",
      "Epoch 17/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1964 | Acc: 62.50% (5/8) | LR: 0.045960\n",
      "Batch 10/113 | Loss: 1.3488 | Acc: 54.55% (48/88) | LR: 0.045897\n",
      "Batch 20/113 | Loss: 0.9689 | Acc: 57.14% (96/168) | LR: 0.045833\n",
      "Batch 30/113 | Loss: 0.6643 | Acc: 55.24% (137/248) | LR: 0.045769\n",
      "Batch 40/113 | Loss: 0.8596 | Acc: 55.79% (183/328) | LR: 0.045704\n",
      "Batch 50/113 | Loss: 0.5580 | Acc: 55.39% (226/408) | LR: 0.045639\n",
      "Batch 60/113 | Loss: 1.2027 | Acc: 55.12% (269/488) | LR: 0.045574\n",
      "Batch 70/113 | Loss: 1.2988 | Acc: 54.23% (308/568) | LR: 0.045508\n",
      "Batch 80/113 | Loss: 1.0156 | Acc: 54.78% (355/648) | LR: 0.045441\n",
      "Batch 90/113 | Loss: 0.8825 | Acc: 54.26% (395/728) | LR: 0.045374\n",
      "Batch 100/113 | Loss: 0.6204 | Acc: 53.96% (436/808) | LR: 0.045307\n",
      "Batch 110/113 | Loss: 1.0647 | Acc: 53.72% (477/888) | LR: 0.045239\n",
      "Train Loss: 0.9719 | Train Acc: 53.98%\n",
      "\n",
      "Epoch 18/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0355 | Acc: 37.50% (3/8) | LR: 0.045219\n",
      "Batch 10/113 | Loss: 0.9001 | Acc: 50.00% (44/88) | LR: 0.045150\n",
      "Batch 20/113 | Loss: 1.0083 | Acc: 49.40% (83/168) | LR: 0.045081\n",
      "Batch 30/113 | Loss: 0.9458 | Acc: 46.77% (116/248) | LR: 0.045012\n",
      "Batch 40/113 | Loss: 0.8615 | Acc: 48.48% (159/328) | LR: 0.044943\n",
      "Batch 50/113 | Loss: 0.8649 | Acc: 49.51% (202/408) | LR: 0.044873\n",
      "Batch 60/113 | Loss: 0.7839 | Acc: 49.80% (243/488) | LR: 0.044802\n",
      "Batch 70/113 | Loss: 1.0166 | Acc: 48.24% (274/568) | LR: 0.044731\n",
      "Batch 80/113 | Loss: 1.4522 | Acc: 48.15% (312/648) | LR: 0.044660\n",
      "Batch 90/113 | Loss: 1.2045 | Acc: 48.76% (355/728) | LR: 0.044588\n",
      "Batch 100/113 | Loss: 0.9259 | Acc: 49.63% (401/808) | LR: 0.044516\n",
      "Batch 110/113 | Loss: 0.9692 | Acc: 48.31% (429/888) | LR: 0.044443\n",
      "Train Loss: 1.0024 | Train Acc: 48.45%\n",
      "\n",
      "Epoch 19/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1260 | Acc: 50.00% (4/8) | LR: 0.044421\n",
      "Batch 10/113 | Loss: 0.9223 | Acc: 57.95% (51/88) | LR: 0.044348\n",
      "Batch 20/113 | Loss: 1.2911 | Acc: 54.17% (91/168) | LR: 0.044275\n",
      "Batch 30/113 | Loss: 0.8898 | Acc: 56.45% (140/248) | LR: 0.044201\n",
      "Batch 40/113 | Loss: 0.8652 | Acc: 55.49% (182/328) | LR: 0.044126\n",
      "Batch 50/113 | Loss: 0.9403 | Acc: 54.90% (224/408) | LR: 0.044051\n",
      "Batch 60/113 | Loss: 0.9054 | Acc: 54.71% (267/488) | LR: 0.043976\n",
      "Batch 70/113 | Loss: 0.9980 | Acc: 52.82% (300/568) | LR: 0.043901\n",
      "Batch 80/113 | Loss: 1.0142 | Acc: 50.77% (329/648) | LR: 0.043825\n",
      "Batch 90/113 | Loss: 0.8910 | Acc: 51.79% (377/728) | LR: 0.043748\n",
      "Batch 100/113 | Loss: 1.9875 | Acc: 52.35% (423/808) | LR: 0.043671\n",
      "Batch 110/113 | Loss: 0.8634 | Acc: 52.25% (464/888) | LR: 0.043594\n",
      "Train Loss: 0.9934 | Train Acc: 51.99%\n",
      "\n",
      "Epoch 20/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8236 | Acc: 62.50% (5/8) | LR: 0.043571\n",
      "Batch 10/113 | Loss: 1.2190 | Acc: 40.91% (36/88) | LR: 0.043493\n",
      "Batch 20/113 | Loss: 0.9607 | Acc: 44.05% (74/168) | LR: 0.043415\n",
      "Batch 30/113 | Loss: 1.0163 | Acc: 48.79% (121/248) | LR: 0.043336\n",
      "Batch 40/113 | Loss: 0.8059 | Acc: 48.78% (160/328) | LR: 0.043257\n",
      "Batch 50/113 | Loss: 1.1032 | Acc: 48.04% (196/408) | LR: 0.043178\n",
      "Batch 60/113 | Loss: 0.9927 | Acc: 49.59% (242/488) | LR: 0.043098\n",
      "Batch 70/113 | Loss: 0.7046 | Acc: 50.70% (288/568) | LR: 0.043018\n",
      "Batch 80/113 | Loss: 1.0429 | Acc: 51.08% (331/648) | LR: 0.042938\n",
      "Batch 90/113 | Loss: 0.8737 | Acc: 51.79% (377/728) | LR: 0.042857\n",
      "Batch 100/113 | Loss: 0.8449 | Acc: 52.48% (424/808) | LR: 0.042776\n",
      "Batch 110/113 | Loss: 1.0904 | Acc: 52.48% (466/888) | LR: 0.042694\n",
      "Train Loss: 0.9717 | Train Acc: 52.43%\n",
      "Evaluating...\n",
      "Val Loss: 1.4221 | Val Acc: 47.51%\n",
      "\n",
      "Epoch 21/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0565 | Acc: 37.50% (3/8) | LR: 0.042669\n",
      "Batch 10/113 | Loss: 0.8305 | Acc: 53.41% (47/88) | LR: 0.042587\n",
      "Batch 20/113 | Loss: 1.1568 | Acc: 53.57% (90/168) | LR: 0.042505\n",
      "Batch 30/113 | Loss: 1.1650 | Acc: 50.00% (124/248) | LR: 0.042422\n",
      "Batch 40/113 | Loss: 0.9557 | Acc: 49.39% (162/328) | LR: 0.042339\n",
      "Batch 50/113 | Loss: 0.6705 | Acc: 50.00% (204/408) | LR: 0.042255\n",
      "Batch 60/113 | Loss: 1.0207 | Acc: 49.18% (240/488) | LR: 0.042171\n",
      "Batch 70/113 | Loss: 0.6774 | Acc: 50.18% (285/568) | LR: 0.042087\n",
      "Batch 80/113 | Loss: 0.7233 | Acc: 51.08% (331/648) | LR: 0.042002\n",
      "Batch 90/113 | Loss: 1.1046 | Acc: 50.96% (371/728) | LR: 0.041917\n",
      "Batch 100/113 | Loss: 1.1270 | Acc: 51.61% (417/808) | LR: 0.041831\n",
      "Batch 110/113 | Loss: 0.7510 | Acc: 51.58% (458/888) | LR: 0.041745\n",
      "Train Loss: 0.9869 | Train Acc: 51.88%\n",
      "\n",
      "Epoch 22/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1559 | Acc: 37.50% (3/8) | LR: 0.041720\n",
      "Batch 10/113 | Loss: 0.8988 | Acc: 56.82% (50/88) | LR: 0.041633\n",
      "Batch 20/113 | Loss: 1.1919 | Acc: 55.36% (93/168) | LR: 0.041547\n",
      "Batch 30/113 | Loss: 0.8153 | Acc: 54.44% (135/248) | LR: 0.041460\n",
      "Batch 40/113 | Loss: 1.2524 | Acc: 53.35% (175/328) | LR: 0.041372\n",
      "Batch 50/113 | Loss: 1.6339 | Acc: 53.92% (220/408) | LR: 0.041285\n",
      "Batch 60/113 | Loss: 1.1392 | Acc: 55.12% (269/488) | LR: 0.041197\n",
      "Batch 70/113 | Loss: 1.0049 | Acc: 54.23% (308/568) | LR: 0.041108\n",
      "Batch 80/113 | Loss: 1.1686 | Acc: 52.78% (342/648) | LR: 0.041019\n",
      "Batch 90/113 | Loss: 0.9932 | Acc: 52.20% (380/728) | LR: 0.040930\n",
      "Batch 100/113 | Loss: 1.1276 | Acc: 51.49% (416/808) | LR: 0.040841\n",
      "Batch 110/113 | Loss: 0.6924 | Acc: 52.59% (467/888) | LR: 0.040751\n",
      "Train Loss: 0.9718 | Train Acc: 52.54%\n",
      "\n",
      "Epoch 23/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1303 | Acc: 50.00% (4/8) | LR: 0.040724\n",
      "Batch 10/113 | Loss: 0.8345 | Acc: 45.45% (40/88) | LR: 0.040634\n",
      "Batch 20/113 | Loss: 0.6987 | Acc: 48.21% (81/168) | LR: 0.040543\n",
      "Batch 30/113 | Loss: 0.5941 | Acc: 48.39% (120/248) | LR: 0.040452\n",
      "Batch 40/113 | Loss: 0.7174 | Acc: 48.78% (160/328) | LR: 0.040361\n",
      "Batch 50/113 | Loss: 0.9904 | Acc: 47.79% (195/408) | LR: 0.040270\n",
      "Batch 60/113 | Loss: 0.7522 | Acc: 48.57% (237/488) | LR: 0.040178\n",
      "Batch 70/113 | Loss: 0.7879 | Acc: 48.59% (276/568) | LR: 0.040085\n",
      "Batch 80/113 | Loss: 0.7156 | Acc: 49.69% (322/648) | LR: 0.039993\n",
      "Batch 90/113 | Loss: 0.7842 | Acc: 50.96% (371/728) | LR: 0.039900\n",
      "Batch 100/113 | Loss: 0.6889 | Acc: 51.86% (419/808) | LR: 0.039807\n",
      "Batch 110/113 | Loss: 1.0438 | Acc: 52.03% (462/888) | LR: 0.039713\n",
      "Train Loss: 0.9648 | Train Acc: 51.99%\n",
      "\n",
      "Epoch 24/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.1022 | Acc: 50.00% (4/8) | LR: 0.039685\n",
      "Batch 10/113 | Loss: 0.8513 | Acc: 62.50% (55/88) | LR: 0.039591\n",
      "Batch 20/113 | Loss: 0.8641 | Acc: 58.93% (99/168) | LR: 0.039497\n",
      "Batch 30/113 | Loss: 1.0776 | Acc: 57.66% (143/248) | LR: 0.039403\n",
      "Batch 40/113 | Loss: 0.8835 | Acc: 57.62% (189/328) | LR: 0.039308\n",
      "Batch 50/113 | Loss: 0.9353 | Acc: 57.84% (236/408) | LR: 0.039213\n",
      "Batch 60/113 | Loss: 0.7337 | Acc: 57.38% (280/488) | LR: 0.039117\n",
      "Batch 70/113 | Loss: 0.7947 | Acc: 56.69% (322/568) | LR: 0.039021\n",
      "Batch 80/113 | Loss: 0.8592 | Acc: 56.64% (367/648) | LR: 0.038925\n",
      "Batch 90/113 | Loss: 0.7985 | Acc: 56.32% (410/728) | LR: 0.038829\n",
      "Batch 100/113 | Loss: 1.2555 | Acc: 56.31% (455/808) | LR: 0.038732\n",
      "Batch 110/113 | Loss: 0.6841 | Acc: 56.08% (498/888) | LR: 0.038635\n",
      "Train Loss: 0.9219 | Train Acc: 55.75%\n",
      "\n",
      "Epoch 25/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7239 | Acc: 75.00% (6/8) | LR: 0.038606\n",
      "Batch 10/113 | Loss: 1.0321 | Acc: 53.41% (47/88) | LR: 0.038509\n",
      "Batch 20/113 | Loss: 0.6003 | Acc: 55.36% (93/168) | LR: 0.038411\n",
      "Batch 30/113 | Loss: 1.0753 | Acc: 52.82% (131/248) | LR: 0.038313\n",
      "Batch 40/113 | Loss: 1.1003 | Acc: 51.52% (169/328) | LR: 0.038215\n",
      "Batch 50/113 | Loss: 0.8258 | Acc: 50.98% (208/408) | LR: 0.038117\n",
      "Batch 60/113 | Loss: 1.0229 | Acc: 51.02% (249/488) | LR: 0.038018\n",
      "Batch 70/113 | Loss: 1.0166 | Acc: 50.35% (286/568) | LR: 0.037919\n",
      "Batch 80/113 | Loss: 0.7444 | Acc: 50.46% (327/648) | LR: 0.037820\n",
      "Batch 90/113 | Loss: 0.8942 | Acc: 51.51% (375/728) | LR: 0.037720\n",
      "Batch 100/113 | Loss: 0.7466 | Acc: 52.10% (421/808) | LR: 0.037620\n",
      "Batch 110/113 | Loss: 0.7468 | Acc: 52.70% (468/888) | LR: 0.037520\n",
      "Train Loss: 0.9451 | Train Acc: 52.65%\n",
      "Evaluating...\n",
      "Val Loss: 1.0735 | Val Acc: 54.14%\n",
      "\n",
      "Epoch 26/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6806 | Acc: 75.00% (6/8) | LR: 0.037490\n",
      "Batch 10/113 | Loss: 1.2545 | Acc: 52.27% (46/88) | LR: 0.037389\n",
      "Batch 20/113 | Loss: 1.1425 | Acc: 55.95% (94/168) | LR: 0.037289\n",
      "Batch 30/113 | Loss: 0.9702 | Acc: 56.85% (141/248) | LR: 0.037188\n",
      "Batch 40/113 | Loss: 1.0697 | Acc: 54.57% (179/328) | LR: 0.037086\n",
      "Batch 50/113 | Loss: 1.0675 | Acc: 54.41% (222/408) | LR: 0.036985\n",
      "Batch 60/113 | Loss: 0.8680 | Acc: 54.92% (268/488) | LR: 0.036883\n",
      "Batch 70/113 | Loss: 1.1266 | Acc: 55.11% (313/568) | LR: 0.036781\n",
      "Batch 80/113 | Loss: 0.8193 | Acc: 54.94% (356/648) | LR: 0.036679\n",
      "Batch 90/113 | Loss: 1.3799 | Acc: 54.12% (394/728) | LR: 0.036576\n",
      "Batch 100/113 | Loss: 0.6868 | Acc: 54.08% (437/808) | LR: 0.036473\n",
      "Batch 110/113 | Loss: 0.8996 | Acc: 54.62% (485/888) | LR: 0.036370\n",
      "Train Loss: 0.9541 | Train Acc: 54.76%\n",
      "\n",
      "Epoch 27/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9124 | Acc: 50.00% (4/8) | LR: 0.036339\n",
      "Batch 10/113 | Loss: 0.8382 | Acc: 57.95% (51/88) | LR: 0.036236\n",
      "Batch 20/113 | Loss: 1.5695 | Acc: 57.74% (97/168) | LR: 0.036132\n",
      "Batch 30/113 | Loss: 1.1632 | Acc: 55.65% (138/248) | LR: 0.036029\n",
      "Batch 40/113 | Loss: 1.0219 | Acc: 54.88% (180/328) | LR: 0.035925\n",
      "Batch 50/113 | Loss: 1.3404 | Acc: 54.41% (222/408) | LR: 0.035820\n",
      "Batch 60/113 | Loss: 1.0716 | Acc: 52.25% (255/488) | LR: 0.035716\n",
      "Batch 70/113 | Loss: 1.0665 | Acc: 52.64% (299/568) | LR: 0.035611\n",
      "Batch 80/113 | Loss: 1.0913 | Acc: 52.16% (338/648) | LR: 0.035506\n",
      "Batch 90/113 | Loss: 1.2870 | Acc: 53.02% (386/728) | LR: 0.035401\n",
      "Batch 100/113 | Loss: 1.3577 | Acc: 53.59% (433/808) | LR: 0.035295\n",
      "Batch 110/113 | Loss: 0.7005 | Acc: 53.49% (475/888) | LR: 0.035190\n",
      "Train Loss: 0.9818 | Train Acc: 53.32%\n",
      "\n",
      "Epoch 28/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8300 | Acc: 62.50% (5/8) | LR: 0.035158\n",
      "Batch 10/113 | Loss: 1.0300 | Acc: 55.68% (49/88) | LR: 0.035052\n",
      "Batch 20/113 | Loss: 0.8198 | Acc: 56.55% (95/168) | LR: 0.034946\n",
      "Batch 30/113 | Loss: 0.9746 | Acc: 58.06% (144/248) | LR: 0.034839\n",
      "Batch 40/113 | Loss: 1.0415 | Acc: 58.23% (191/328) | LR: 0.034733\n",
      "Batch 50/113 | Loss: 1.3119 | Acc: 59.31% (242/408) | LR: 0.034626\n",
      "Batch 60/113 | Loss: 0.8299 | Acc: 59.02% (288/488) | LR: 0.034519\n",
      "Batch 70/113 | Loss: 0.6941 | Acc: 59.33% (337/568) | LR: 0.034412\n",
      "Batch 80/113 | Loss: 1.2154 | Acc: 59.88% (388/648) | LR: 0.034304\n",
      "Batch 90/113 | Loss: 0.9805 | Acc: 59.89% (436/728) | LR: 0.034197\n",
      "Batch 100/113 | Loss: 1.0473 | Acc: 59.90% (484/808) | LR: 0.034089\n",
      "Batch 110/113 | Loss: 0.8435 | Acc: 59.35% (527/888) | LR: 0.033981\n",
      "Train Loss: 0.9021 | Train Acc: 59.07%\n",
      "\n",
      "Epoch 29/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6281 | Acc: 75.00% (6/8) | LR: 0.033948\n",
      "Batch 10/113 | Loss: 0.9034 | Acc: 63.64% (56/88) | LR: 0.033840\n",
      "Batch 20/113 | Loss: 1.0587 | Acc: 61.31% (103/168) | LR: 0.033732\n",
      "Batch 30/113 | Loss: 1.4474 | Acc: 61.29% (152/248) | LR: 0.033623\n",
      "Batch 40/113 | Loss: 1.1636 | Acc: 58.84% (193/328) | LR: 0.033514\n",
      "Batch 50/113 | Loss: 0.8048 | Acc: 59.07% (241/408) | LR: 0.033405\n",
      "Batch 60/113 | Loss: 0.6001 | Acc: 58.81% (287/488) | LR: 0.033296\n",
      "Batch 70/113 | Loss: 0.6983 | Acc: 59.86% (340/568) | LR: 0.033187\n",
      "Batch 80/113 | Loss: 0.7636 | Acc: 59.41% (385/648) | LR: 0.033077\n",
      "Batch 90/113 | Loss: 1.0668 | Acc: 58.24% (424/728) | LR: 0.032967\n",
      "Batch 100/113 | Loss: 1.1016 | Acc: 58.79% (475/808) | LR: 0.032858\n",
      "Batch 110/113 | Loss: 1.0385 | Acc: 59.23% (526/888) | LR: 0.032747\n",
      "Train Loss: 0.8955 | Train Acc: 59.07%\n",
      "\n",
      "Epoch 30/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.3208 | Acc: 25.00% (2/8) | LR: 0.032714\n",
      "Batch 10/113 | Loss: 1.0134 | Acc: 50.00% (44/88) | LR: 0.032604\n",
      "Batch 20/113 | Loss: 1.0790 | Acc: 47.62% (80/168) | LR: 0.032494\n",
      "Batch 30/113 | Loss: 0.7216 | Acc: 50.40% (125/248) | LR: 0.032383\n",
      "Batch 40/113 | Loss: 0.9965 | Acc: 52.13% (171/328) | LR: 0.032272\n",
      "Batch 50/113 | Loss: 1.3102 | Acc: 53.19% (217/408) | LR: 0.032161\n",
      "Batch 60/113 | Loss: 1.4361 | Acc: 52.66% (257/488) | LR: 0.032050\n",
      "Batch 70/113 | Loss: 0.6806 | Acc: 53.52% (304/568) | LR: 0.031939\n",
      "Batch 80/113 | Loss: 0.9252 | Acc: 55.25% (358/648) | LR: 0.031828\n",
      "Batch 90/113 | Loss: 1.3444 | Acc: 55.36% (403/728) | LR: 0.031716\n",
      "Batch 100/113 | Loss: 0.7098 | Acc: 56.06% (453/808) | LR: 0.031605\n",
      "Batch 110/113 | Loss: 1.3542 | Acc: 55.52% (493/888) | LR: 0.031493\n",
      "Train Loss: 0.9279 | Train Acc: 55.53%\n",
      "Evaluating...\n",
      "Val Loss: 1.1081 | Val Acc: 58.56%\n",
      "New best model with accuracy: 58.56%\n",
      "\n",
      "Epoch 31/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8069 | Acc: 62.50% (5/8) | LR: 0.031459\n",
      "Batch 10/113 | Loss: 0.8888 | Acc: 55.68% (49/88) | LR: 0.031347\n",
      "Batch 20/113 | Loss: 1.0237 | Acc: 55.95% (94/168) | LR: 0.031235\n",
      "Batch 30/113 | Loss: 0.9492 | Acc: 59.27% (147/248) | LR: 0.031123\n",
      "Batch 40/113 | Loss: 0.7804 | Acc: 60.37% (198/328) | LR: 0.031011\n",
      "Batch 50/113 | Loss: 1.1824 | Acc: 60.29% (246/408) | LR: 0.030898\n",
      "Batch 60/113 | Loss: 0.8748 | Acc: 60.25% (294/488) | LR: 0.030785\n",
      "Batch 70/113 | Loss: 0.7161 | Acc: 59.33% (337/568) | LR: 0.030673\n",
      "Batch 80/113 | Loss: 0.9562 | Acc: 57.41% (372/648) | LR: 0.030560\n",
      "Batch 90/113 | Loss: 0.6976 | Acc: 57.14% (416/728) | LR: 0.030447\n",
      "Batch 100/113 | Loss: 0.8071 | Acc: 57.67% (466/808) | LR: 0.030334\n",
      "Batch 110/113 | Loss: 0.6473 | Acc: 58.00% (515/888) | LR: 0.030220\n",
      "Train Loss: 0.8883 | Train Acc: 58.19%\n",
      "\n",
      "Epoch 32/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0608 | Acc: 37.50% (3/8) | LR: 0.030186\n",
      "Batch 10/113 | Loss: 0.9370 | Acc: 45.45% (40/88) | LR: 0.030073\n",
      "Batch 20/113 | Loss: 0.9682 | Acc: 51.19% (86/168) | LR: 0.029960\n",
      "Batch 30/113 | Loss: 1.1117 | Acc: 54.84% (136/248) | LR: 0.029846\n",
      "Batch 40/113 | Loss: 0.5503 | Acc: 55.18% (181/328) | LR: 0.029732\n",
      "Batch 50/113 | Loss: 1.1728 | Acc: 55.15% (225/408) | LR: 0.029619\n",
      "Batch 60/113 | Loss: 0.6690 | Acc: 57.79% (282/488) | LR: 0.029505\n",
      "Batch 70/113 | Loss: 0.6821 | Acc: 57.92% (329/568) | LR: 0.029391\n",
      "Batch 80/113 | Loss: 1.1244 | Acc: 57.25% (371/648) | LR: 0.029277\n",
      "Batch 90/113 | Loss: 0.7464 | Acc: 57.01% (415/728) | LR: 0.029162\n",
      "Batch 100/113 | Loss: 0.6707 | Acc: 57.80% (467/808) | LR: 0.029048\n",
      "Batch 110/113 | Loss: 0.8523 | Acc: 57.88% (514/888) | LR: 0.028934\n",
      "Train Loss: 0.8811 | Train Acc: 57.74%\n",
      "\n",
      "Epoch 33/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5998 | Acc: 87.50% (7/8) | LR: 0.028899\n",
      "Batch 10/113 | Loss: 0.9340 | Acc: 64.77% (57/88) | LR: 0.028785\n",
      "Batch 20/113 | Loss: 1.1087 | Acc: 57.74% (97/168) | LR: 0.028670\n",
      "Batch 30/113 | Loss: 0.8367 | Acc: 52.02% (129/248) | LR: 0.028556\n",
      "Batch 40/113 | Loss: 0.9145 | Acc: 51.52% (169/328) | LR: 0.028441\n",
      "Batch 50/113 | Loss: 0.7868 | Acc: 53.19% (217/408) | LR: 0.028326\n",
      "Batch 60/113 | Loss: 1.1402 | Acc: 53.28% (260/488) | LR: 0.028211\n",
      "Batch 70/113 | Loss: 1.4786 | Acc: 53.35% (303/568) | LR: 0.028097\n",
      "Batch 80/113 | Loss: 0.8191 | Acc: 53.24% (345/648) | LR: 0.027982\n",
      "Batch 90/113 | Loss: 0.7587 | Acc: 54.53% (397/728) | LR: 0.027867\n",
      "Batch 100/113 | Loss: 1.0092 | Acc: 54.58% (441/808) | LR: 0.027751\n",
      "Batch 110/113 | Loss: 0.9086 | Acc: 54.95% (488/888) | LR: 0.027636\n",
      "Train Loss: 0.9254 | Train Acc: 55.09%\n",
      "\n",
      "Epoch 34/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8220 | Acc: 75.00% (6/8) | LR: 0.027602\n",
      "Batch 10/113 | Loss: 0.7181 | Acc: 62.50% (55/88) | LR: 0.027486\n",
      "Batch 20/113 | Loss: 0.7067 | Acc: 58.33% (98/168) | LR: 0.027371\n",
      "Batch 30/113 | Loss: 0.7096 | Acc: 58.47% (145/248) | LR: 0.027256\n",
      "Batch 40/113 | Loss: 1.0099 | Acc: 58.23% (191/328) | LR: 0.027140\n",
      "Batch 50/113 | Loss: 0.9156 | Acc: 57.11% (233/408) | LR: 0.027025\n",
      "Batch 60/113 | Loss: 1.1538 | Acc: 57.79% (282/488) | LR: 0.026910\n",
      "Batch 70/113 | Loss: 0.7030 | Acc: 57.57% (327/568) | LR: 0.026794\n",
      "Batch 80/113 | Loss: 0.8814 | Acc: 57.72% (374/648) | LR: 0.026678\n",
      "Batch 90/113 | Loss: 0.8996 | Acc: 58.38% (425/728) | LR: 0.026563\n",
      "Batch 100/113 | Loss: 0.8902 | Acc: 57.92% (468/808) | LR: 0.026447\n",
      "Batch 110/113 | Loss: 0.9202 | Acc: 58.00% (515/888) | LR: 0.026332\n",
      "Train Loss: 0.9021 | Train Acc: 57.74%\n",
      "\n",
      "Epoch 35/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5839 | Acc: 75.00% (6/8) | LR: 0.026297\n",
      "Batch 10/113 | Loss: 1.0069 | Acc: 60.23% (53/88) | LR: 0.026181\n",
      "Batch 20/113 | Loss: 0.7041 | Acc: 58.93% (99/168) | LR: 0.026065\n",
      "Batch 30/113 | Loss: 0.5482 | Acc: 59.27% (147/248) | LR: 0.025950\n",
      "Batch 40/113 | Loss: 0.7524 | Acc: 57.62% (189/328) | LR: 0.025834\n",
      "Batch 50/113 | Loss: 0.6074 | Acc: 59.07% (241/408) | LR: 0.025718\n",
      "Batch 60/113 | Loss: 1.3108 | Acc: 58.20% (284/488) | LR: 0.025602\n",
      "Batch 70/113 | Loss: 1.1915 | Acc: 57.92% (329/568) | LR: 0.025486\n",
      "Batch 80/113 | Loss: 0.8118 | Acc: 58.64% (380/648) | LR: 0.025371\n",
      "Batch 90/113 | Loss: 0.6897 | Acc: 59.20% (431/728) | LR: 0.025255\n",
      "Batch 100/113 | Loss: 0.7706 | Acc: 58.79% (475/808) | LR: 0.025139\n",
      "Batch 110/113 | Loss: 0.6806 | Acc: 58.78% (522/888) | LR: 0.025023\n",
      "Train Loss: 0.8822 | Train Acc: 58.74%\n",
      "Evaluating...\n",
      "Val Loss: 1.2331 | Val Acc: 59.67%\n",
      "New best model with accuracy: 59.67%\n",
      "\n",
      "Epoch 36/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6219 | Acc: 75.00% (6/8) | LR: 0.024988\n",
      "Batch 10/113 | Loss: 1.4159 | Acc: 57.95% (51/88) | LR: 0.024873\n",
      "Batch 20/113 | Loss: 1.0724 | Acc: 61.90% (104/168) | LR: 0.024757\n",
      "Batch 30/113 | Loss: 1.6567 | Acc: 58.87% (146/248) | LR: 0.024641\n",
      "Batch 40/113 | Loss: 1.2622 | Acc: 58.84% (193/328) | LR: 0.024525\n",
      "Batch 50/113 | Loss: 0.8486 | Acc: 60.29% (246/408) | LR: 0.024409\n",
      "Batch 60/113 | Loss: 0.8748 | Acc: 60.25% (294/488) | LR: 0.024293\n",
      "Batch 70/113 | Loss: 0.8976 | Acc: 59.33% (337/568) | LR: 0.024178\n",
      "Batch 80/113 | Loss: 0.7003 | Acc: 60.03% (389/648) | LR: 0.024062\n",
      "Batch 90/113 | Loss: 0.3331 | Acc: 60.71% (442/728) | LR: 0.023946\n",
      "Batch 100/113 | Loss: 1.0418 | Acc: 60.27% (487/808) | LR: 0.023830\n",
      "Batch 110/113 | Loss: 1.2705 | Acc: 59.91% (532/888) | LR: 0.023715\n",
      "Train Loss: 0.8818 | Train Acc: 59.85%\n",
      "\n",
      "Epoch 37/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7216 | Acc: 75.00% (6/8) | LR: 0.023680\n",
      "Batch 10/113 | Loss: 0.8679 | Acc: 57.95% (51/88) | LR: 0.023564\n",
      "Batch 20/113 | Loss: 0.8200 | Acc: 57.74% (97/168) | LR: 0.023449\n",
      "Batch 30/113 | Loss: 0.7144 | Acc: 58.47% (145/248) | LR: 0.023333\n",
      "Batch 40/113 | Loss: 0.7739 | Acc: 59.15% (194/328) | LR: 0.023218\n",
      "Batch 50/113 | Loss: 0.7095 | Acc: 59.31% (242/408) | LR: 0.023102\n",
      "Batch 60/113 | Loss: 0.5943 | Acc: 57.99% (283/488) | LR: 0.022987\n",
      "Batch 70/113 | Loss: 0.7563 | Acc: 58.45% (332/568) | LR: 0.022871\n",
      "Batch 80/113 | Loss: 0.6408 | Acc: 59.72% (387/648) | LR: 0.022756\n",
      "Batch 90/113 | Loss: 1.2556 | Acc: 59.20% (431/728) | LR: 0.022640\n",
      "Batch 100/113 | Loss: 1.0024 | Acc: 59.16% (478/808) | LR: 0.022525\n",
      "Batch 110/113 | Loss: 0.4183 | Acc: 59.46% (528/888) | LR: 0.022410\n",
      "Train Loss: 0.8439 | Train Acc: 59.62%\n",
      "\n",
      "Epoch 38/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9966 | Acc: 50.00% (4/8) | LR: 0.022375\n",
      "Batch 10/113 | Loss: 0.7280 | Acc: 54.55% (48/88) | LR: 0.022260\n",
      "Batch 20/113 | Loss: 0.7818 | Acc: 60.12% (101/168) | LR: 0.022145\n",
      "Batch 30/113 | Loss: 0.9106 | Acc: 58.47% (145/248) | LR: 0.022030\n",
      "Batch 40/113 | Loss: 0.7607 | Acc: 59.15% (194/328) | LR: 0.021915\n",
      "Batch 50/113 | Loss: 0.4742 | Acc: 61.27% (250/408) | LR: 0.021800\n",
      "Batch 60/113 | Loss: 0.4413 | Acc: 61.89% (302/488) | LR: 0.021685\n",
      "Batch 70/113 | Loss: 1.1655 | Acc: 60.74% (345/568) | LR: 0.021570\n",
      "Batch 80/113 | Loss: 0.9138 | Acc: 59.57% (386/648) | LR: 0.021456\n",
      "Batch 90/113 | Loss: 0.9896 | Acc: 59.20% (431/728) | LR: 0.021341\n",
      "Batch 100/113 | Loss: 1.0071 | Acc: 59.78% (483/808) | LR: 0.021226\n",
      "Batch 110/113 | Loss: 0.5879 | Acc: 60.02% (533/888) | LR: 0.021112\n",
      "Train Loss: 0.8717 | Train Acc: 59.96%\n",
      "\n",
      "Epoch 39/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7513 | Acc: 62.50% (5/8) | LR: 0.021078\n",
      "Batch 10/113 | Loss: 0.6380 | Acc: 57.95% (51/88) | LR: 0.020963\n",
      "Batch 20/113 | Loss: 0.8574 | Acc: 57.74% (97/168) | LR: 0.020849\n",
      "Batch 30/113 | Loss: 1.2934 | Acc: 54.03% (134/248) | LR: 0.020735\n",
      "Batch 40/113 | Loss: 0.8543 | Acc: 55.79% (183/328) | LR: 0.020621\n",
      "Batch 50/113 | Loss: 0.7585 | Acc: 55.88% (228/408) | LR: 0.020507\n",
      "Batch 60/113 | Loss: 0.8995 | Acc: 56.76% (277/488) | LR: 0.020393\n",
      "Batch 70/113 | Loss: 0.7445 | Acc: 58.10% (330/568) | LR: 0.020279\n",
      "Batch 80/113 | Loss: 0.7169 | Acc: 58.49% (379/648) | LR: 0.020165\n",
      "Batch 90/113 | Loss: 0.8262 | Acc: 58.10% (423/728) | LR: 0.020052\n",
      "Batch 100/113 | Loss: 0.6768 | Acc: 58.91% (476/808) | LR: 0.019938\n",
      "Batch 110/113 | Loss: 0.9843 | Acc: 60.02% (533/888) | LR: 0.019825\n",
      "Train Loss: 0.8598 | Train Acc: 60.18%\n",
      "\n",
      "Epoch 40/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0194 | Acc: 37.50% (3/8) | LR: 0.019791\n",
      "Batch 10/113 | Loss: 1.0706 | Acc: 54.55% (48/88) | LR: 0.019678\n",
      "Batch 20/113 | Loss: 1.1010 | Acc: 61.31% (103/168) | LR: 0.019565\n",
      "Batch 30/113 | Loss: 1.0497 | Acc: 57.26% (142/248) | LR: 0.019451\n",
      "Batch 40/113 | Loss: 1.0157 | Acc: 55.49% (182/328) | LR: 0.019339\n",
      "Batch 50/113 | Loss: 0.8472 | Acc: 56.37% (230/408) | LR: 0.019226\n",
      "Batch 60/113 | Loss: 0.6674 | Acc: 57.58% (281/488) | LR: 0.019113\n",
      "Batch 70/113 | Loss: 0.8172 | Acc: 58.80% (334/568) | LR: 0.019001\n",
      "Batch 80/113 | Loss: 0.8002 | Acc: 58.64% (380/648) | LR: 0.018888\n",
      "Batch 90/113 | Loss: 0.4289 | Acc: 58.65% (427/728) | LR: 0.018776\n",
      "Batch 100/113 | Loss: 0.8854 | Acc: 58.79% (475/808) | LR: 0.018664\n",
      "Batch 110/113 | Loss: 0.3609 | Acc: 59.68% (530/888) | LR: 0.018552\n",
      "Train Loss: 0.8420 | Train Acc: 59.62%\n",
      "Evaluating...\n",
      "Val Loss: 1.3932 | Val Acc: 55.25%\n",
      "\n",
      "Epoch 41/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8802 | Acc: 37.50% (3/8) | LR: 0.018518\n",
      "Batch 10/113 | Loss: 1.2128 | Acc: 59.09% (52/88) | LR: 0.018407\n",
      "Batch 20/113 | Loss: 0.6999 | Acc: 58.33% (98/168) | LR: 0.018295\n",
      "Batch 30/113 | Loss: 0.7576 | Acc: 61.69% (153/248) | LR: 0.018183\n",
      "Batch 40/113 | Loss: 0.8234 | Acc: 62.20% (204/328) | LR: 0.018072\n",
      "Batch 50/113 | Loss: 1.0819 | Acc: 63.97% (261/408) | LR: 0.017961\n",
      "Batch 60/113 | Loss: 0.6322 | Acc: 64.55% (315/488) | LR: 0.017850\n",
      "Batch 70/113 | Loss: 0.9216 | Acc: 64.44% (366/568) | LR: 0.017739\n",
      "Batch 80/113 | Loss: 0.6098 | Acc: 64.04% (415/648) | LR: 0.017628\n",
      "Batch 90/113 | Loss: 1.0058 | Acc: 62.91% (458/728) | LR: 0.017517\n",
      "Batch 100/113 | Loss: 0.6985 | Acc: 62.87% (508/808) | LR: 0.017407\n",
      "Batch 110/113 | Loss: 1.0138 | Acc: 62.16% (552/888) | LR: 0.017297\n",
      "Train Loss: 0.8395 | Train Acc: 62.39%\n",
      "\n",
      "Epoch 42/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5006 | Acc: 100.00% (8/8) | LR: 0.017264\n",
      "Batch 10/113 | Loss: 0.9384 | Acc: 61.36% (54/88) | LR: 0.017153\n",
      "Batch 20/113 | Loss: 0.8053 | Acc: 63.69% (107/168) | LR: 0.017044\n",
      "Batch 30/113 | Loss: 1.2367 | Acc: 60.08% (149/248) | LR: 0.016934\n",
      "Batch 40/113 | Loss: 0.8038 | Acc: 60.06% (197/328) | LR: 0.016824\n",
      "Batch 50/113 | Loss: 1.0512 | Acc: 58.82% (240/408) | LR: 0.016715\n",
      "Batch 60/113 | Loss: 1.0292 | Acc: 58.40% (285/488) | LR: 0.016606\n",
      "Batch 70/113 | Loss: 0.7202 | Acc: 58.98% (335/568) | LR: 0.016497\n",
      "Batch 80/113 | Loss: 0.6286 | Acc: 58.80% (381/648) | LR: 0.016388\n",
      "Batch 90/113 | Loss: 1.0340 | Acc: 60.03% (437/728) | LR: 0.016279\n",
      "Batch 100/113 | Loss: 0.7186 | Acc: 60.64% (490/808) | LR: 0.016171\n",
      "Batch 110/113 | Loss: 0.6859 | Acc: 61.37% (545/888) | LR: 0.016062\n",
      "Train Loss: 0.8400 | Train Acc: 61.06%\n",
      "\n",
      "Epoch 43/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5409 | Acc: 87.50% (7/8) | LR: 0.016030\n",
      "Batch 10/113 | Loss: 0.8586 | Acc: 63.64% (56/88) | LR: 0.015922\n",
      "Batch 20/113 | Loss: 0.7894 | Acc: 63.10% (106/168) | LR: 0.015814\n",
      "Batch 30/113 | Loss: 0.7488 | Acc: 64.52% (160/248) | LR: 0.015706\n",
      "Batch 40/113 | Loss: 0.9428 | Acc: 66.16% (217/328) | LR: 0.015599\n",
      "Batch 50/113 | Loss: 0.9686 | Acc: 64.95% (265/408) | LR: 0.015492\n",
      "Batch 60/113 | Loss: 0.8912 | Acc: 64.34% (314/488) | LR: 0.015385\n",
      "Batch 70/113 | Loss: 1.0451 | Acc: 63.73% (362/568) | LR: 0.015278\n",
      "Batch 80/113 | Loss: 0.7110 | Acc: 62.04% (402/648) | LR: 0.015171\n",
      "Batch 90/113 | Loss: 0.5730 | Acc: 61.95% (451/728) | LR: 0.015065\n",
      "Batch 100/113 | Loss: 0.7030 | Acc: 62.62% (506/808) | LR: 0.014959\n",
      "Batch 110/113 | Loss: 0.4770 | Acc: 63.29% (562/888) | LR: 0.014853\n",
      "Train Loss: 0.8057 | Train Acc: 63.38%\n",
      "\n",
      "Epoch 44/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8606 | Acc: 75.00% (6/8) | LR: 0.014821\n",
      "Batch 10/113 | Loss: 1.2989 | Acc: 63.64% (56/88) | LR: 0.014715\n",
      "Batch 20/113 | Loss: 0.7427 | Acc: 63.10% (106/168) | LR: 0.014610\n",
      "Batch 30/113 | Loss: 1.0012 | Acc: 62.50% (155/248) | LR: 0.014505\n",
      "Batch 40/113 | Loss: 0.8226 | Acc: 64.33% (211/328) | LR: 0.014400\n",
      "Batch 50/113 | Loss: 0.4454 | Acc: 63.73% (260/408) | LR: 0.014295\n",
      "Batch 60/113 | Loss: 0.5175 | Acc: 64.34% (314/488) | LR: 0.014190\n",
      "Batch 70/113 | Loss: 0.8936 | Acc: 63.91% (363/568) | LR: 0.014086\n",
      "Batch 80/113 | Loss: 0.7837 | Acc: 63.43% (411/648) | LR: 0.013982\n",
      "Batch 90/113 | Loss: 1.0330 | Acc: 62.77% (457/728) | LR: 0.013878\n",
      "Batch 100/113 | Loss: 0.6213 | Acc: 62.75% (507/808) | LR: 0.013774\n",
      "Batch 110/113 | Loss: 0.6356 | Acc: 62.50% (555/888) | LR: 0.013671\n",
      "Train Loss: 0.8260 | Train Acc: 62.39%\n",
      "\n",
      "Epoch 45/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6673 | Acc: 75.00% (6/8) | LR: 0.013640\n",
      "Batch 10/113 | Loss: 0.9095 | Acc: 71.59% (63/88) | LR: 0.013537\n",
      "Batch 20/113 | Loss: 0.6161 | Acc: 66.07% (111/168) | LR: 0.013434\n",
      "Batch 30/113 | Loss: 1.1395 | Acc: 68.15% (169/248) | LR: 0.013331\n",
      "Batch 40/113 | Loss: 1.1068 | Acc: 65.24% (214/328) | LR: 0.013229\n",
      "Batch 50/113 | Loss: 0.7058 | Acc: 63.97% (261/408) | LR: 0.013127\n",
      "Batch 60/113 | Loss: 0.8114 | Acc: 64.14% (313/488) | LR: 0.013025\n",
      "Batch 70/113 | Loss: 0.4449 | Acc: 64.08% (364/568) | LR: 0.012924\n",
      "Batch 80/113 | Loss: 0.6142 | Acc: 64.04% (415/648) | LR: 0.012822\n",
      "Batch 90/113 | Loss: 1.1668 | Acc: 64.01% (466/728) | LR: 0.012721\n",
      "Batch 100/113 | Loss: 0.5569 | Acc: 64.48% (521/808) | LR: 0.012621\n",
      "Batch 110/113 | Loss: 0.9531 | Acc: 64.19% (570/888) | LR: 0.012520\n",
      "Train Loss: 0.7974 | Train Acc: 64.16%\n",
      "Evaluating...\n",
      "Val Loss: 1.1244 | Val Acc: 57.46%\n",
      "\n",
      "Epoch 46/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6907 | Acc: 75.00% (6/8) | LR: 0.012490\n",
      "Batch 10/113 | Loss: 0.7889 | Acc: 60.23% (53/88) | LR: 0.012390\n",
      "Batch 20/113 | Loss: 1.0171 | Acc: 59.52% (100/168) | LR: 0.012290\n",
      "Batch 30/113 | Loss: 1.0546 | Acc: 57.66% (143/248) | LR: 0.012190\n",
      "Batch 40/113 | Loss: 0.9238 | Acc: 60.06% (197/328) | LR: 0.012091\n",
      "Batch 50/113 | Loss: 0.8668 | Acc: 59.80% (244/408) | LR: 0.011992\n",
      "Batch 60/113 | Loss: 0.6238 | Acc: 61.48% (300/488) | LR: 0.011893\n",
      "Batch 70/113 | Loss: 0.7123 | Acc: 61.62% (350/568) | LR: 0.011795\n",
      "Batch 80/113 | Loss: 0.7325 | Acc: 62.50% (405/648) | LR: 0.011696\n",
      "Batch 90/113 | Loss: 0.8990 | Acc: 61.95% (451/728) | LR: 0.011598\n",
      "Batch 100/113 | Loss: 0.6821 | Acc: 62.25% (503/808) | LR: 0.011501\n",
      "Batch 110/113 | Loss: 0.7321 | Acc: 62.50% (555/888) | LR: 0.011403\n",
      "Train Loss: 0.8242 | Train Acc: 62.28%\n",
      "\n",
      "Epoch 47/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.0899 | Acc: 75.00% (6/8) | LR: 0.011374\n",
      "Batch 10/113 | Loss: 0.3943 | Acc: 69.32% (61/88) | LR: 0.011277\n",
      "Batch 20/113 | Loss: 0.7295 | Acc: 67.26% (113/168) | LR: 0.011181\n",
      "Batch 30/113 | Loss: 0.8762 | Acc: 63.31% (157/248) | LR: 0.011084\n",
      "Batch 40/113 | Loss: 1.0950 | Acc: 62.20% (204/328) | LR: 0.010988\n",
      "Batch 50/113 | Loss: 1.1524 | Acc: 62.01% (253/408) | LR: 0.010892\n",
      "Batch 60/113 | Loss: 0.8611 | Acc: 61.68% (301/488) | LR: 0.010797\n",
      "Batch 70/113 | Loss: 0.6811 | Acc: 63.20% (359/568) | LR: 0.010702\n",
      "Batch 80/113 | Loss: 0.5320 | Acc: 63.58% (412/648) | LR: 0.010607\n",
      "Batch 90/113 | Loss: 1.1506 | Acc: 62.91% (458/728) | LR: 0.010512\n",
      "Batch 100/113 | Loss: 0.7086 | Acc: 62.75% (507/808) | LR: 0.010418\n",
      "Batch 110/113 | Loss: 0.7552 | Acc: 63.29% (562/888) | LR: 0.010324\n",
      "Train Loss: 0.8063 | Train Acc: 63.27%\n",
      "\n",
      "Epoch 48/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 1.2332 | Acc: 37.50% (3/8) | LR: 0.010296\n",
      "Batch 10/113 | Loss: 0.9328 | Acc: 56.82% (50/88) | LR: 0.010202\n",
      "Batch 20/113 | Loss: 0.5808 | Acc: 59.52% (100/168) | LR: 0.010109\n",
      "Batch 30/113 | Loss: 0.7062 | Acc: 60.89% (151/248) | LR: 0.010016\n",
      "Batch 40/113 | Loss: 0.8852 | Acc: 61.59% (202/328) | LR: 0.009924\n",
      "Batch 50/113 | Loss: 0.8706 | Acc: 62.50% (255/408) | LR: 0.009832\n",
      "Batch 60/113 | Loss: 0.8682 | Acc: 62.70% (306/488) | LR: 0.009740\n",
      "Batch 70/113 | Loss: 0.7065 | Acc: 63.03% (358/568) | LR: 0.009648\n",
      "Batch 80/113 | Loss: 0.7037 | Acc: 63.58% (412/648) | LR: 0.009557\n",
      "Batch 90/113 | Loss: 0.7179 | Acc: 63.74% (464/728) | LR: 0.009466\n",
      "Batch 100/113 | Loss: 0.4917 | Acc: 63.49% (513/808) | LR: 0.009375\n",
      "Batch 110/113 | Loss: 0.5264 | Acc: 64.19% (570/888) | LR: 0.009285\n",
      "Train Loss: 0.7847 | Train Acc: 63.94%\n",
      "\n",
      "Epoch 49/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9891 | Acc: 62.50% (5/8) | LR: 0.009258\n",
      "Batch 10/113 | Loss: 0.7693 | Acc: 60.23% (53/88) | LR: 0.009168\n",
      "Batch 20/113 | Loss: 0.8140 | Acc: 60.12% (101/168) | LR: 0.009079\n",
      "Batch 30/113 | Loss: 1.1537 | Acc: 62.90% (156/248) | LR: 0.008990\n",
      "Batch 40/113 | Loss: 0.9963 | Acc: 64.63% (212/328) | LR: 0.008901\n",
      "Batch 50/113 | Loss: 0.7460 | Acc: 64.71% (264/408) | LR: 0.008812\n",
      "Batch 60/113 | Loss: 1.0816 | Acc: 63.93% (312/488) | LR: 0.008724\n",
      "Batch 70/113 | Loss: 1.3232 | Acc: 63.91% (363/568) | LR: 0.008636\n",
      "Batch 80/113 | Loss: 0.7758 | Acc: 64.35% (417/648) | LR: 0.008549\n",
      "Batch 90/113 | Loss: 0.5149 | Acc: 64.29% (468/728) | LR: 0.008462\n",
      "Batch 100/113 | Loss: 0.5464 | Acc: 64.98% (525/808) | LR: 0.008375\n",
      "Batch 110/113 | Loss: 0.8246 | Acc: 64.19% (570/888) | LR: 0.008289\n",
      "Train Loss: 0.7832 | Train Acc: 64.38%\n",
      "\n",
      "Epoch 50/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.4610 | Acc: 75.00% (6/8) | LR: 0.008263\n",
      "Batch 10/113 | Loss: 0.9598 | Acc: 65.91% (58/88) | LR: 0.008177\n",
      "Batch 20/113 | Loss: 0.8435 | Acc: 66.67% (112/168) | LR: 0.008092\n",
      "Batch 30/113 | Loss: 0.7080 | Acc: 66.13% (164/248) | LR: 0.008007\n",
      "Batch 40/113 | Loss: 1.0764 | Acc: 64.63% (212/328) | LR: 0.007922\n",
      "Batch 50/113 | Loss: 1.0831 | Acc: 65.69% (268/408) | LR: 0.007837\n",
      "Batch 60/113 | Loss: 1.0357 | Acc: 67.01% (327/488) | LR: 0.007753\n",
      "Batch 70/113 | Loss: 0.6295 | Acc: 66.20% (376/568) | LR: 0.007670\n",
      "Batch 80/113 | Loss: 0.7511 | Acc: 66.05% (428/648) | LR: 0.007586\n",
      "Batch 90/113 | Loss: 1.1140 | Acc: 65.93% (480/728) | LR: 0.007503\n",
      "Batch 100/113 | Loss: 0.4503 | Acc: 66.09% (534/808) | LR: 0.007421\n",
      "Batch 110/113 | Loss: 0.9251 | Acc: 66.44% (590/888) | LR: 0.007339\n",
      "Train Loss: 0.7324 | Train Acc: 66.59%\n",
      "Evaluating...\n",
      "Val Loss: 1.1901 | Val Acc: 59.12%\n",
      "\n",
      "Epoch 51/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6714 | Acc: 62.50% (5/8) | LR: 0.007314\n",
      "Batch 10/113 | Loss: 0.9949 | Acc: 56.82% (50/88) | LR: 0.007232\n",
      "Batch 20/113 | Loss: 0.7187 | Acc: 61.90% (104/168) | LR: 0.007151\n",
      "Batch 30/113 | Loss: 1.3626 | Acc: 60.89% (151/248) | LR: 0.007070\n",
      "Batch 40/113 | Loss: 0.5502 | Acc: 63.11% (207/328) | LR: 0.006990\n",
      "Batch 50/113 | Loss: 0.6940 | Acc: 64.46% (263/408) | LR: 0.006910\n",
      "Batch 60/113 | Loss: 0.8448 | Acc: 63.93% (312/488) | LR: 0.006830\n",
      "Batch 70/113 | Loss: 0.7113 | Acc: 64.61% (367/568) | LR: 0.006750\n",
      "Batch 80/113 | Loss: 0.8154 | Acc: 65.59% (425/648) | LR: 0.006671\n",
      "Batch 90/113 | Loss: 0.9330 | Acc: 65.25% (475/728) | LR: 0.006593\n",
      "Batch 100/113 | Loss: 0.7314 | Acc: 65.35% (528/808) | LR: 0.006515\n",
      "Batch 110/113 | Loss: 0.7578 | Acc: 65.88% (585/888) | LR: 0.006437\n",
      "Train Loss: 0.7679 | Train Acc: 66.04%\n",
      "\n",
      "Epoch 52/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.9191 | Acc: 62.50% (5/8) | LR: 0.006414\n",
      "Batch 10/113 | Loss: 1.0483 | Acc: 67.05% (59/88) | LR: 0.006336\n",
      "Batch 20/113 | Loss: 0.9937 | Acc: 71.43% (120/168) | LR: 0.006259\n",
      "Batch 30/113 | Loss: 0.5622 | Acc: 68.55% (170/248) | LR: 0.006183\n",
      "Batch 40/113 | Loss: 0.6482 | Acc: 67.68% (222/328) | LR: 0.006107\n",
      "Batch 50/113 | Loss: 0.6321 | Acc: 68.38% (279/408) | LR: 0.006031\n",
      "Batch 60/113 | Loss: 1.0411 | Acc: 69.47% (339/488) | LR: 0.005956\n",
      "Batch 70/113 | Loss: 1.2361 | Acc: 69.01% (392/568) | LR: 0.005881\n",
      "Batch 80/113 | Loss: 0.9308 | Acc: 68.36% (443/648) | LR: 0.005807\n",
      "Batch 90/113 | Loss: 0.4896 | Acc: 68.54% (499/728) | LR: 0.005733\n",
      "Batch 100/113 | Loss: 0.4792 | Acc: 68.07% (550/808) | LR: 0.005659\n",
      "Batch 110/113 | Loss: 0.5835 | Acc: 68.02% (604/888) | LR: 0.005586\n",
      "Train Loss: 0.7258 | Train Acc: 68.25%\n",
      "\n",
      "Epoch 53/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6146 | Acc: 75.00% (6/8) | LR: 0.005564\n",
      "Batch 10/113 | Loss: 0.7138 | Acc: 69.32% (61/88) | LR: 0.005491\n",
      "Batch 20/113 | Loss: 0.9401 | Acc: 67.26% (113/168) | LR: 0.005419\n",
      "Batch 30/113 | Loss: 0.7535 | Acc: 66.13% (164/248) | LR: 0.005347\n",
      "Batch 40/113 | Loss: 0.5706 | Acc: 64.94% (213/328) | LR: 0.005276\n",
      "Batch 50/113 | Loss: 0.8626 | Acc: 65.69% (268/408) | LR: 0.005205\n",
      "Batch 60/113 | Loss: 0.5448 | Acc: 66.60% (325/488) | LR: 0.005134\n",
      "Batch 70/113 | Loss: 1.4586 | Acc: 67.96% (386/568) | LR: 0.005064\n",
      "Batch 80/113 | Loss: 0.8026 | Acc: 67.59% (438/648) | LR: 0.004995\n",
      "Batch 90/113 | Loss: 1.3640 | Acc: 66.90% (487/728) | LR: 0.004925\n",
      "Batch 100/113 | Loss: 0.5819 | Acc: 66.34% (536/808) | LR: 0.004857\n",
      "Batch 110/113 | Loss: 0.7245 | Acc: 65.65% (583/888) | LR: 0.004788\n",
      "Train Loss: 0.7595 | Train Acc: 65.71%\n",
      "\n",
      "Epoch 54/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6995 | Acc: 75.00% (6/8) | LR: 0.004768\n",
      "Batch 10/113 | Loss: 0.6774 | Acc: 61.36% (54/88) | LR: 0.004700\n",
      "Batch 20/113 | Loss: 1.3190 | Acc: 63.10% (106/168) | LR: 0.004633\n",
      "Batch 30/113 | Loss: 1.1539 | Acc: 62.90% (156/248) | LR: 0.004566\n",
      "Batch 40/113 | Loss: 0.7303 | Acc: 65.24% (214/328) | LR: 0.004499\n",
      "Batch 50/113 | Loss: 0.6071 | Acc: 64.95% (265/408) | LR: 0.004433\n",
      "Batch 60/113 | Loss: 0.4900 | Acc: 66.19% (323/488) | LR: 0.004367\n",
      "Batch 70/113 | Loss: 0.5212 | Acc: 65.85% (374/568) | LR: 0.004302\n",
      "Batch 80/113 | Loss: 0.8742 | Acc: 66.36% (430/648) | LR: 0.004237\n",
      "Batch 90/113 | Loss: 0.9248 | Acc: 66.48% (484/728) | LR: 0.004173\n",
      "Batch 100/113 | Loss: 0.5663 | Acc: 68.32% (552/808) | LR: 0.004109\n",
      "Batch 110/113 | Loss: 0.9268 | Acc: 67.57% (600/888) | LR: 0.004046\n",
      "Train Loss: 0.6908 | Train Acc: 67.81%\n",
      "\n",
      "Epoch 55/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6175 | Acc: 75.00% (6/8) | LR: 0.004027\n",
      "Batch 10/113 | Loss: 0.8034 | Acc: 65.91% (58/88) | LR: 0.003964\n",
      "Batch 20/113 | Loss: 0.5057 | Acc: 66.67% (112/168) | LR: 0.003902\n",
      "Batch 30/113 | Loss: 0.7307 | Acc: 68.15% (169/248) | LR: 0.003840\n",
      "Batch 40/113 | Loss: 0.3967 | Acc: 67.99% (223/328) | LR: 0.003778\n",
      "Batch 50/113 | Loss: 0.6941 | Acc: 67.65% (276/408) | LR: 0.003717\n",
      "Batch 60/113 | Loss: 0.7592 | Acc: 67.01% (327/488) | LR: 0.003657\n",
      "Batch 70/113 | Loss: 0.8053 | Acc: 66.73% (379/568) | LR: 0.003597\n",
      "Batch 80/113 | Loss: 0.9155 | Acc: 67.44% (437/648) | LR: 0.003537\n",
      "Batch 90/113 | Loss: 0.6224 | Acc: 67.86% (494/728) | LR: 0.003478\n",
      "Batch 100/113 | Loss: 0.7378 | Acc: 67.70% (547/808) | LR: 0.003419\n",
      "Batch 110/113 | Loss: 0.5952 | Acc: 67.00% (595/888) | LR: 0.003361\n",
      "Train Loss: 0.7335 | Train Acc: 66.48%\n",
      "Evaluating...\n",
      "Val Loss: 1.1820 | Val Acc: 60.22%\n",
      "New best model with accuracy: 60.22%\n",
      "\n",
      "Epoch 56/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7071 | Acc: 75.00% (6/8) | LR: 0.003344\n",
      "Batch 10/113 | Loss: 0.7294 | Acc: 68.18% (60/88) | LR: 0.003286\n",
      "Batch 20/113 | Loss: 0.8874 | Acc: 69.05% (116/168) | LR: 0.003229\n",
      "Batch 30/113 | Loss: 0.9393 | Acc: 67.74% (168/248) | LR: 0.003172\n",
      "Batch 40/113 | Loss: 0.9529 | Acc: 69.21% (227/328) | LR: 0.003116\n",
      "Batch 50/113 | Loss: 0.9868 | Acc: 69.12% (282/408) | LR: 0.003060\n",
      "Batch 60/113 | Loss: 0.6729 | Acc: 68.65% (335/488) | LR: 0.003005\n",
      "Batch 70/113 | Loss: 1.1997 | Acc: 69.19% (393/568) | LR: 0.002950\n",
      "Batch 80/113 | Loss: 0.9468 | Acc: 69.91% (453/648) | LR: 0.002896\n",
      "Batch 90/113 | Loss: 0.8366 | Acc: 69.51% (506/728) | LR: 0.002842\n",
      "Batch 100/113 | Loss: 0.8328 | Acc: 69.18% (559/808) | LR: 0.002788\n",
      "Batch 110/113 | Loss: 1.0372 | Acc: 69.14% (614/888) | LR: 0.002735\n",
      "Train Loss: 0.7139 | Train Acc: 69.14%\n",
      "Evaluating...\n",
      "Val Loss: 1.1098 | Val Acc: 62.98%\n",
      "New best model with accuracy: 62.98%\n",
      "\n",
      "Epoch 57/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.8291 | Acc: 62.50% (5/8) | LR: 0.002720\n",
      "Batch 10/113 | Loss: 0.9771 | Acc: 68.18% (60/88) | LR: 0.002667\n",
      "Batch 20/113 | Loss: 0.5266 | Acc: 70.24% (118/168) | LR: 0.002615\n",
      "Batch 30/113 | Loss: 0.4286 | Acc: 73.39% (182/248) | LR: 0.002564\n",
      "Batch 40/113 | Loss: 0.4684 | Acc: 74.70% (245/328) | LR: 0.002513\n",
      "Batch 50/113 | Loss: 0.8314 | Acc: 74.02% (302/408) | LR: 0.002463\n",
      "Batch 60/113 | Loss: 0.6383 | Acc: 73.77% (360/488) | LR: 0.002413\n",
      "Batch 70/113 | Loss: 0.8157 | Acc: 73.77% (419/568) | LR: 0.002364\n",
      "Batch 80/113 | Loss: 0.8745 | Acc: 72.84% (472/648) | LR: 0.002315\n",
      "Batch 90/113 | Loss: 0.5232 | Acc: 72.80% (530/728) | LR: 0.002266\n",
      "Batch 100/113 | Loss: 0.8842 | Acc: 72.03% (582/808) | LR: 0.002218\n",
      "Batch 110/113 | Loss: 0.5831 | Acc: 71.96% (639/888) | LR: 0.002171\n",
      "Train Loss: 0.6704 | Train Acc: 72.35%\n",
      "Evaluating...\n",
      "Val Loss: 1.0620 | Val Acc: 61.88%\n",
      "\n",
      "Epoch 58/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7034 | Acc: 62.50% (5/8) | LR: 0.002157\n",
      "Batch 10/113 | Loss: 1.1488 | Acc: 62.50% (55/88) | LR: 0.002110\n",
      "Batch 20/113 | Loss: 0.4048 | Acc: 64.88% (109/168) | LR: 0.002064\n",
      "Batch 30/113 | Loss: 0.7258 | Acc: 66.94% (166/248) | LR: 0.002018\n",
      "Batch 40/113 | Loss: 1.1446 | Acc: 67.99% (223/328) | LR: 0.001972\n",
      "Batch 50/113 | Loss: 0.5518 | Acc: 67.65% (276/408) | LR: 0.001927\n",
      "Batch 60/113 | Loss: 0.8524 | Acc: 68.24% (333/488) | LR: 0.001883\n",
      "Batch 70/113 | Loss: 0.4920 | Acc: 69.37% (394/568) | LR: 0.001839\n",
      "Batch 80/113 | Loss: 0.7021 | Acc: 68.83% (446/648) | LR: 0.001796\n",
      "Batch 90/113 | Loss: 0.4568 | Acc: 68.68% (500/728) | LR: 0.001753\n",
      "Batch 100/113 | Loss: 0.7978 | Acc: 68.56% (554/808) | LR: 0.001711\n",
      "Batch 110/113 | Loss: 1.0066 | Acc: 68.36% (607/888) | LR: 0.001669\n",
      "Train Loss: 0.6971 | Train Acc: 68.25%\n",
      "Evaluating...\n",
      "Val Loss: 1.1481 | Val Acc: 60.22%\n",
      "\n",
      "Epoch 59/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6501 | Acc: 75.00% (6/8) | LR: 0.001656\n",
      "Batch 10/113 | Loss: 0.4680 | Acc: 77.27% (68/88) | LR: 0.001615\n",
      "Batch 20/113 | Loss: 1.1875 | Acc: 72.62% (122/168) | LR: 0.001574\n",
      "Batch 30/113 | Loss: 0.4288 | Acc: 69.35% (172/248) | LR: 0.001534\n",
      "Batch 40/113 | Loss: 0.4150 | Acc: 69.51% (228/328) | LR: 0.001495\n",
      "Batch 50/113 | Loss: 0.4955 | Acc: 70.83% (289/408) | LR: 0.001455\n",
      "Batch 60/113 | Loss: 0.8583 | Acc: 70.70% (345/488) | LR: 0.001417\n",
      "Batch 70/113 | Loss: 0.6179 | Acc: 70.60% (401/568) | LR: 0.001378\n",
      "Batch 80/113 | Loss: 0.6105 | Acc: 71.30% (462/648) | LR: 0.001341\n",
      "Batch 90/113 | Loss: 0.3977 | Acc: 71.02% (517/728) | LR: 0.001304\n",
      "Batch 100/113 | Loss: 0.3918 | Acc: 70.79% (572/808) | LR: 0.001267\n",
      "Batch 110/113 | Loss: 0.6395 | Acc: 70.95% (630/888) | LR: 0.001231\n",
      "Train Loss: 0.6625 | Train Acc: 70.91%\n",
      "Evaluating...\n",
      "Val Loss: 1.2043 | Val Acc: 60.77%\n",
      "\n",
      "Epoch 60/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.6326 | Acc: 75.00% (6/8) | LR: 0.001220\n",
      "Batch 10/113 | Loss: 0.8785 | Acc: 65.91% (58/88) | LR: 0.001185\n",
      "Batch 20/113 | Loss: 0.6255 | Acc: 67.26% (113/168) | LR: 0.001150\n",
      "Batch 30/113 | Loss: 0.4479 | Acc: 68.55% (170/248) | LR: 0.001115\n",
      "Batch 40/113 | Loss: 1.0267 | Acc: 67.07% (220/328) | LR: 0.001081\n",
      "Batch 50/113 | Loss: 0.5529 | Acc: 66.42% (271/408) | LR: 0.001048\n",
      "Batch 60/113 | Loss: 0.3749 | Acc: 67.62% (330/488) | LR: 0.001015\n",
      "Batch 70/113 | Loss: 0.4974 | Acc: 68.13% (387/568) | LR: 0.000982\n",
      "Batch 80/113 | Loss: 0.5338 | Acc: 68.36% (443/648) | LR: 0.000950\n",
      "Batch 90/113 | Loss: 1.1475 | Acc: 68.82% (501/728) | LR: 0.000919\n",
      "Batch 100/113 | Loss: 0.1633 | Acc: 68.69% (555/808) | LR: 0.000888\n",
      "Batch 110/113 | Loss: 0.5890 | Acc: 69.14% (614/888) | LR: 0.000858\n",
      "Train Loss: 0.6704 | Train Acc: 69.36%\n",
      "Evaluating...\n",
      "Val Loss: 1.1979 | Val Acc: 60.77%\n",
      "\n",
      "Epoch 61/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7020 | Acc: 75.00% (6/8) | LR: 0.000849\n",
      "Batch 10/113 | Loss: 0.7879 | Acc: 81.82% (72/88) | LR: 0.000819\n",
      "Batch 20/113 | Loss: 0.5462 | Acc: 73.21% (123/168) | LR: 0.000790\n",
      "Batch 30/113 | Loss: 0.6797 | Acc: 72.58% (180/248) | LR: 0.000761\n",
      "Batch 40/113 | Loss: 0.7249 | Acc: 70.12% (230/328) | LR: 0.000733\n",
      "Batch 50/113 | Loss: 0.3810 | Acc: 70.10% (286/408) | LR: 0.000706\n",
      "Batch 60/113 | Loss: 0.5678 | Acc: 70.08% (342/488) | LR: 0.000679\n",
      "Batch 70/113 | Loss: 0.6629 | Acc: 69.37% (394/568) | LR: 0.000652\n",
      "Batch 80/113 | Loss: 0.5854 | Acc: 69.29% (449/648) | LR: 0.000626\n",
      "Batch 90/113 | Loss: 0.7526 | Acc: 69.64% (507/728) | LR: 0.000601\n",
      "Batch 100/113 | Loss: 0.5755 | Acc: 69.93% (565/808) | LR: 0.000576\n",
      "Batch 110/113 | Loss: 0.8744 | Acc: 69.71% (619/888) | LR: 0.000551\n",
      "Train Loss: 0.6706 | Train Acc: 69.58%\n",
      "Evaluating...\n",
      "Val Loss: 1.1946 | Val Acc: 61.33%\n",
      "\n",
      "Epoch 62/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.4217 | Acc: 87.50% (7/8) | LR: 0.000544\n",
      "Batch 10/113 | Loss: 0.6742 | Acc: 77.27% (68/88) | LR: 0.000520\n",
      "Batch 20/113 | Loss: 0.8490 | Acc: 72.02% (121/168) | LR: 0.000497\n",
      "Batch 30/113 | Loss: 0.6848 | Acc: 72.18% (179/248) | LR: 0.000474\n",
      "Batch 40/113 | Loss: 0.8706 | Acc: 70.12% (230/328) | LR: 0.000452\n",
      "Batch 50/113 | Loss: 0.4728 | Acc: 71.32% (291/408) | LR: 0.000430\n",
      "Batch 60/113 | Loss: 0.6653 | Acc: 70.90% (346/488) | LR: 0.000409\n",
      "Batch 70/113 | Loss: 0.5840 | Acc: 71.65% (407/568) | LR: 0.000389\n",
      "Batch 80/113 | Loss: 0.6664 | Acc: 71.30% (462/648) | LR: 0.000368\n",
      "Batch 90/113 | Loss: 0.4349 | Acc: 71.84% (523/728) | LR: 0.000349\n",
      "Batch 100/113 | Loss: 1.2085 | Acc: 71.16% (575/808) | LR: 0.000330\n",
      "Batch 110/113 | Loss: 0.3658 | Acc: 71.28% (633/888) | LR: 0.000311\n",
      "Train Loss: 0.6412 | Train Acc: 71.57%\n",
      "Evaluating...\n",
      "Val Loss: 1.1702 | Val Acc: 58.56%\n",
      "\n",
      "Epoch 63/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.7811 | Acc: 75.00% (6/8) | LR: 0.000306\n",
      "Batch 10/113 | Loss: 0.7461 | Acc: 67.05% (59/88) | LR: 0.000288\n",
      "Batch 20/113 | Loss: 0.4677 | Acc: 70.24% (118/168) | LR: 0.000271\n",
      "Batch 30/113 | Loss: 0.5777 | Acc: 72.18% (179/248) | LR: 0.000254\n",
      "Batch 40/113 | Loss: 0.4723 | Acc: 72.87% (239/328) | LR: 0.000238\n",
      "Batch 50/113 | Loss: 0.4405 | Acc: 72.79% (297/408) | LR: 0.000222\n",
      "Batch 60/113 | Loss: 0.4822 | Acc: 72.54% (354/488) | LR: 0.000207\n",
      "Batch 70/113 | Loss: 0.6891 | Acc: 72.18% (410/568) | LR: 0.000193\n",
      "Batch 80/113 | Loss: 0.8222 | Acc: 70.99% (460/648) | LR: 0.000178\n",
      "Batch 90/113 | Loss: 1.2001 | Acc: 70.47% (513/728) | LR: 0.000165\n",
      "Batch 100/113 | Loss: 0.5986 | Acc: 70.17% (567/808) | LR: 0.000152\n",
      "Batch 110/113 | Loss: 0.6922 | Acc: 70.27% (624/888) | LR: 0.000139\n",
      "Train Loss: 0.6505 | Train Acc: 70.35%\n",
      "Evaluating...\n",
      "Val Loss: 1.1774 | Val Acc: 59.12%\n",
      "\n",
      "Epoch 64/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5027 | Acc: 87.50% (7/8) | LR: 0.000136\n",
      "Batch 10/113 | Loss: 0.6976 | Acc: 69.32% (61/88) | LR: 0.000124\n",
      "Batch 20/113 | Loss: 0.5449 | Acc: 69.05% (116/168) | LR: 0.000113\n",
      "Batch 30/113 | Loss: 0.7087 | Acc: 68.95% (171/248) | LR: 0.000102\n",
      "Batch 40/113 | Loss: 0.5182 | Acc: 68.29% (224/328) | LR: 0.000092\n",
      "Batch 50/113 | Loss: 0.7966 | Acc: 67.65% (276/408) | LR: 0.000082\n",
      "Batch 60/113 | Loss: 0.4730 | Acc: 68.44% (334/488) | LR: 0.000073\n",
      "Batch 70/113 | Loss: 0.5137 | Acc: 68.84% (391/568) | LR: 0.000064\n",
      "Batch 80/113 | Loss: 0.6542 | Acc: 69.91% (453/648) | LR: 0.000056\n",
      "Batch 90/113 | Loss: 0.5979 | Acc: 69.92% (509/728) | LR: 0.000049\n",
      "Batch 100/113 | Loss: 0.5987 | Acc: 69.93% (565/808) | LR: 0.000042\n",
      "Batch 110/113 | Loss: 0.6435 | Acc: 70.16% (623/888) | LR: 0.000035\n",
      "Train Loss: 0.6682 | Train Acc: 70.46%\n",
      "Evaluating...\n",
      "Val Loss: 1.1772 | Val Acc: 60.77%\n",
      "\n",
      "Epoch 65/65\n",
      "Training...\n",
      "Batch 0/113 | Loss: 0.5060 | Acc: 87.50% (7/8) | LR: 0.000034\n",
      "Batch 10/113 | Loss: 0.4214 | Acc: 79.55% (70/88) | LR: 0.000028\n",
      "Batch 20/113 | Loss: 0.9853 | Acc: 71.43% (120/168) | LR: 0.000023\n",
      "Batch 30/113 | Loss: 0.4770 | Acc: 68.15% (169/248) | LR: 0.000018\n",
      "Batch 40/113 | Loss: 0.3502 | Acc: 68.60% (225/328) | LR: 0.000014\n",
      "Batch 50/113 | Loss: 0.6304 | Acc: 69.12% (282/408) | LR: 0.000010\n",
      "Batch 60/113 | Loss: 0.6252 | Acc: 69.88% (341/488) | LR: 0.000007\n",
      "Batch 70/113 | Loss: 0.3293 | Acc: 71.30% (405/568) | LR: 0.000005\n",
      "Batch 80/113 | Loss: 0.3165 | Acc: 71.14% (461/648) | LR: 0.000003\n",
      "Batch 90/113 | Loss: 0.6999 | Acc: 71.57% (521/728) | LR: 0.000001\n",
      "Batch 100/113 | Loss: 0.7775 | Acc: 71.78% (580/808) | LR: 0.000000\n",
      "Batch 110/113 | Loss: 0.6821 | Acc: 71.51% (635/888) | LR: 0.000000\n",
      "Train Loss: 0.6340 | Train Acc: 71.79%\n",
      "Evaluating...\n",
      "Val Loss: 1.3138 | Val Acc: 58.56%\n",
      "Training completed. Best accuracy: 62.98% at epoch 56\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Debug",
   "id": "36050c493cacf0a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:34:54.012771Z",
     "start_time": "2025-11-25T23:34:35.033051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target, _ in eval_loader:\n",
    "        # keep only samples where target ∈ {0,1,2}\n",
    "        mask = target < 3\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        data = data[mask].float().to(device)\n",
    "        target = target[mask].long().to(device)\n",
    "\n",
    "        out,_ = model(data)\n",
    "        pred = out.argmax(1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(pred)\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "print(classification_report(\n",
    "    all_targets, all_preds,\n",
    "    target_names=[\"Transit\", \"Social_People\", \"Play_Object_Normal\"]\n",
    "))"
   ],
   "id": "3020ec0ac393d6d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Transit       0.74      0.63      0.68       111\n",
      "     Social_People       0.53      0.54      0.54        35\n",
      "Play_Object_Normal       0.33      0.49      0.40        35\n",
      "\n",
      "          accuracy                           0.59       181\n",
      "         macro avg       0.54      0.55      0.54       181\n",
      "      weighted avg       0.62      0.59      0.60       181\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T22:46:02.974862Z",
     "start_time": "2025-11-25T16:35:54.166533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ],
   "id": "6e513e792fc04a2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
