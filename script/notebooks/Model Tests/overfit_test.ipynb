{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Before Running please adjust to new split strategy to ./workdir/fold_XX",
   "id": "5b49c25e743012fe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:24.950161Z",
     "start_time": "2025-11-21T03:13:24.933451Z"
    }
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "from types import SimpleNamespace\n",
    "\n",
    "yaml_path = \"../../config/playground/mpgcn.yaml\"\n",
    "\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "def to_ns(d):\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: to_ns(v) for k, v in d.items()})\n",
    "    elif isinstance(d, list):\n",
    "        return [to_ns(x) for x in d]\n",
    "    return d\n",
    "\n",
    "args = to_ns(cfg)\n",
    "args.config_path = yaml_path\n",
    "print(\"Loaded YAML config.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded YAML config.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:26.561524Z",
     "start_time": "2025-11-21T03:13:26.558478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args.work_dir = \"../../workdir\"\n",
    "args.dataset_args.root_folder = \"../../workdir\"\n",
    "args.dataset_args.object_folder = \"../../workdir\"\n",
    "\n",
    "print(\"Root folder:\", args.dataset_args.root_folder)"
   ],
   "id": "907e6966e29fd9f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder: ../../workdir\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:31.346692Z",
     "start_time": "2025-11-21T03:13:28.272249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.dataset import create as create_dataset\n",
    "from src.initializer import Initializer\n",
    "from src.model import create as create_model"
   ],
   "id": "e3577bbcd189a656",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:31.948805Z",
     "start_time": "2025-11-21T03:13:31.944412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "train_labels_path = os.path.join(args.dataset_args.root_folder, \"train_label.pkl\")\n",
    "\n",
    "with open(train_labels_path, \"rb\") as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "labels_arr = np.array([l for l, _ in train_labels])\n",
    "observed_classes = int(labels_arr.max()) + 1\n",
    "\n",
    "print(\"Observed label classes:\", observed_classes)"
   ],
   "id": "2ecc4dac93051f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed label classes: 6\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:34.157237Z",
     "start_time": "2025-11-21T03:13:34.154328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args.dataset_args.debug = True\n",
    "args.dataset_args.augment = False\n",
    "\n",
    "# Inject correct class count into model_args\n",
    "args.model_args.num_class = observed_classes\n",
    "\n",
    "print(\"Model will be built with num_class =\", args.model_args.num_class)"
   ],
   "id": "8154dbd8f8b1f06a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be built with num_class = 6\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:35.957048Z",
     "start_time": "2025-11-21T03:13:35.930154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feeders, data_shape, num_class, A, parts = create_dataset(\n",
    "    args.dataset,\n",
    "    **vars(args.dataset_args)\n",
    ")\n",
    "\n",
    "print(\"train samples:\", len(feeders[\"train\"]))\n",
    "print(\"eval samples :\", len(feeders[\"eval\"]))\n",
    "print(\"data shape   :\", data_shape)\n",
    "print(\"num classes  :\", num_class)"
   ],
   "id": "63eb4fe37098dcdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 64\n",
      "eval samples : 64\n",
      "data shape   : [4, 6, 48, 96, 1]\n",
      "num classes  : 6\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:37.868142Z",
     "start_time": "2025-11-21T03:13:37.698880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from src.model.MPGCN import MPGCN\n",
    "\n",
    "# Convert adjacency matrix\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "A_tensor = A_tensor.cuda() if torch.cuda.is_available() else A_tensor\n",
    "\n",
    "# Build the model with ALL required arguments\n",
    "model = MPGCN(\n",
    "    data_shape=data_shape,     # shape: [4, 6, 48, 96, 1]\n",
    "    A=A_tensor,                # adjacency, now torch.Tensor\n",
    "    parts=parts,               # <-- REQUIRED\n",
    "    num_class=args.model_args.num_class,\n",
    "    use_att=args.model_args.use_att,\n",
    "    kernel_size=args.model_args.kernel_size,\n",
    "    dilation=args.model_args.dilation,\n",
    "    reduct_ratio=args.model_args.reduct_ratio\n",
    ")\n",
    "\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "print(\"Model successfully built!\")"
   ],
   "id": "311448b29917cd11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully built!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:39.324311Z",
     "start_time": "2025-11-21T03:13:39.317812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample, label, clip = feeders[\"train\"][0]\n",
    "\n",
    "x = torch.tensor(sample).float().unsqueeze(0)  # add batch dim\n",
    "y = torch.tensor([label])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "\n",
    "print(\"Input tensor:\", x.shape)\n",
    "print(\"Label:\", y)"
   ],
   "id": "16f1d315ae73103b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor: torch.Size([1, 4, 6, 48, 96, 1])\n",
      "Label: tensor([1])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:41.338264Z",
     "start_time": "2025-11-21T03:13:41.228822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_tuple = model(x)\n",
    "logits = out_tuple[0]   # MP-GCN returns (output, feature_maps)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ],
   "id": "b11825e4b9e5ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 6])\n",
      "Logits: tensor([[ 0.0183,  0.0206, -0.0080,  0.0081, -0.0122,  0.0369]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:45.563311Z",
     "start_time": "2025-11-21T03:13:45.030479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.9,\n",
    "    nesterov=True,\n",
    "    weight_decay=0.0002\n",
    ")"
   ],
   "id": "5873548cfb53f470",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:13:46.901714Z",
     "start_time": "2025-11-21T03:13:46.898862Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = torch.nn.CrossEntropyLoss()",
   "id": "27c18fcb90120b93",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T03:14:29.688055Z",
     "start_time": "2025-11-21T03:13:48.591902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"Starting 1-sample overfit test...\")\n",
    "\n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits, _ = model(x)\n",
    "    loss = criterion(logits, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = logits.argmax(dim=1).item()\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Iter {i:03d} | Loss = {loss.item():.6f} | Pred = {pred}, True = {y.item()}\")\n",
    "\n",
    "print(\"DONE.\")"
   ],
   "id": "5cbe4a5cdd9e4c25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1-sample overfit test...\n",
      "Iter 000 | Loss = 1.781923 | Pred = 5, True = 1\n",
      "Iter 020 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 040 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 060 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 080 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 100 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 120 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 140 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 160 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "Iter 180 | Loss = 0.000000 | Pred = 1, True = 1\n",
      "DONE.\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
