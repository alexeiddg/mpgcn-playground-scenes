{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MPGCN Playground Pipeline",
   "id": "286f893d08dd69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T22:54:29.527161Z",
     "start_time": "2025-11-29T22:54:28.647655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from types import SimpleNamespace\n",
    "from src.reader import Playground_Reader\n",
    "from src.dataset import create as create_dataset\n",
    "from src.model.MPGCN import MPGCN\n",
    "\n",
    "# IMPORTANT:\n",
    "# Run the Workdir Cleanup BEFORE running reader.start()\n",
    "# because camera IDs require regenerating folds.\n",
    "\n",
    "def to_ns(d):\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: to_ns(v) for k, v in d.items()})\n",
    "    elif isinstance(d, list):\n",
    "        return [to_ns(x) for x in d]\n",
    "    return d\n",
    "\n",
    "def resolve_path(path: str):\n",
    "    if path.startswith(\"./\"):\n",
    "        base = os.path.abspath(\".\")\n",
    "        return os.path.join(base, path[2:])\n",
    "    return path"
   ],
   "id": "652ed021505c11bf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ⚠️ Careful, this removes the splits from ./workdir DO NOT RUN if you are not regenerating the folds",
   "id": "793f7bcee069b0e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T22:54:32.333912Z",
     "start_time": "2025-11-29T22:54:32.275347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "workdir_path = \"./workdir\"\n",
    "\n",
    "if os.path.exists(workdir_path) and os.path.isdir(workdir_path):\n",
    "    for item in os.listdir(workdir_path):\n",
    "        item_path = os.path.join(workdir_path, item)\n",
    "        try:\n",
    "            if os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "            else:\n",
    "                os.remove(item_path)\n",
    "            print(f\"Removed: {item}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {item}: {e}\")\n",
    "    print(\"Workdir cleanup complete!\")\n",
    "else:\n",
    "    print(\"./workdir directory not found or is not a directory\")"
   ],
   "id": "5b15f1fe98680fb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: fold_07_train.txt\n",
      "Removed: fold_13_train.txt\n",
      "Removed: fold_01_eval.txt\n",
      "Removed: fold_00_eval.txt\n",
      "Removed: fold_summary.json\n",
      "Removed: fold_20_train.txt\n",
      "Removed: fold_19\n",
      "Removed: fold_16_eval.txt\n",
      "Removed: fold_17_eval.txt\n",
      "Removed: fold_21\n",
      "Removed: fold_01_train.txt\n",
      "Removed: fold_17\n",
      "Removed: fold_15_train.txt\n",
      "Removed: fold_10\n",
      "Removed: fold_22_eval.txt\n",
      "Removed: fold_23_eval.txt\n",
      "Removed: fold_11\n",
      "Removed: fold_16\n",
      "Removed: fold_20\n",
      "Removed: fold_18_train.txt\n",
      "Removed: area2idx.json\n",
      "Removed: fold_18\n",
      "Removed: fold_05\n",
      "Removed: fold_02\n",
      "Removed: fold_12_train.txt\n",
      "Removed: fold_06_train.txt\n",
      "Removed: fold_11_eval.txt\n",
      "Removed: fold_10_eval.txt\n",
      "Removed: fold_summary_actual.json\n",
      "Removed: fold_24_eval.txt\n",
      "Removed: fold_03\n",
      "Removed: fold_04\n",
      "Removed: fold_21_train.txt\n",
      "Removed: fold_14_train.txt\n",
      "Removed: fold_06_eval.txt\n",
      "Removed: fold_07_eval.txt\n",
      "Removed: fold_00_train.txt\n",
      "Removed: fold_19_train.txt\n",
      "Removed: fold_24_train.txt\n",
      "Removed: fold_21_eval.txt\n",
      "Removed: fold_20_eval.txt\n",
      "Removed: fold_05_train.txt\n",
      "Removed: fold_11_train.txt\n",
      "Removed: fold_15_eval.txt\n",
      "Removed: fold_14_eval.txt\n",
      "Removed: fold_08_train.txt\n",
      "Removed: fold_22\n",
      "Removed: fold_03_train.txt\n",
      "Removed: fold_13\n",
      "Removed: fold_17_train.txt\n",
      "Removed: fold_14\n",
      "Removed: fold_08_eval.txt\n",
      "Removed: fold_09_eval.txt\n",
      "Removed: fold_22_train.txt\n",
      "Removed: fold_15\n",
      "Removed: fold_12\n",
      "Removed: fold_24\n",
      "Removed: fold_23\n",
      "Removed: fold_02_eval.txt\n",
      "Removed: fold_03_eval.txt\n",
      "Removed: fold_01\n",
      "Removed: fold_10_train.txt\n",
      "Removed: fold_06\n",
      "Removed: fold_04_train.txt\n",
      "Removed: fold_08\n",
      "Removed: fold_09\n",
      "Removed: fold_09_train.txt\n",
      "Removed: fold_05_eval.txt\n",
      "Removed: fold_04_eval.txt\n",
      "Removed: fold_07\n",
      "Removed: fold_00\n",
      "Removed: fold_16_train.txt\n",
      "Removed: fold_02_train.txt\n",
      "Removed: fold_06_J\n",
      "Removed: fold_23_train.txt\n",
      "Removed: fold_18_eval.txt\n",
      "Removed: fold_19_eval.txt\n",
      "Removed: fold_12_eval.txt\n",
      "Removed: fold_13_eval.txt\n",
      "Workdir cleanup complete!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reader GENDATA (Run only once if no files in ./workdir or tensor shapes change)",
   "id": "7fd7c8e23c811872"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T22:54:44.877423Z",
     "start_time": "2025-11-29T22:54:36.905501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gendata_yaml_path = \"./config/playground_gendata.yaml\"\n",
    "with open(gendata_yaml_path, \"r\") as f:\n",
    "    gendata_cfg = yaml.safe_load(f)\n",
    "\n",
    "dataset_args = gendata_cfg[\"dataset_args\"]\n",
    "\n",
    "dataset_args[\"dataset_root_folder\"] = resolve_path(dataset_args[\"dataset_root_folder\"])\n",
    "dataset_args[\"out_folder\"] = resolve_path(dataset_args[\"out_folder\"])\n",
    "\n",
    "print(\"Root folder resolved →\", dataset_args[\"dataset_root_folder\"])\n",
    "print(\"Output folder resolved →\", dataset_args[\"out_folder\"])\n",
    "\n",
    "reader = Playground_Reader(\n",
    "    dataset_root_folder=dataset_args[\"dataset_root_folder\"],\n",
    "    out_folder=dataset_args[\"out_folder\"],\n",
    "    label_csv_path=\"./data/processed/mpgcn_labels.csv\",\n",
    "    num_frame=dataset_args[\"num_frame\"],\n",
    ")\n",
    "reader.start()\n",
    "\n",
    "# Choose a fold to train\n",
    "FOLD_ID = 0\n",
    "fold_dir = f\"{dataset_args['out_folder']}/fold_{FOLD_ID:02d}\"\n",
    "\n",
    "train_data_path = os.path.join(fold_dir, \"train_data.npy\")\n",
    "train_obj_path = os.path.join(fold_dir, \"train_object_data.npy\")\n",
    "train_label_path = os.path.join(fold_dir, \"train_label.pkl\")\n",
    "\n",
    "eval_data_path = os.path.join(fold_dir, \"eval_data.npy\")\n",
    "eval_obj_path = os.path.join(fold_dir, \"eval_object_data.npy\")\n",
    "eval_label_path = os.path.join(fold_dir, \"eval_label.pkl\")\n",
    "\n",
    "cam_path = os.path.join(fold_dir, \"train_camera.npy\")\n",
    "print(\"Camera file exists:\", os.path.exists(cam_path))\n",
    "print(\"Using fold:\", fold_dir)"
   ],
   "id": "577e347dc23e036c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder resolved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "Output folder resolved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir\n",
      "Starting dataset build from CSV with repeated stratified K-folds...\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 00 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 5270.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 1904.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 00 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_00\n",
      "Unique object shapes found for fold 00 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_00\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 01 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24296.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5326.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 01 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_01\n",
      "Unique object shapes found for fold 01 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_01\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 02 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24531.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5436.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 02 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_02\n",
      "Unique object shapes found for fold 02 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_02\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 03 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 10249.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5146.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 03 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_03\n",
      "Unique object shapes found for fold 03 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_03\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 04 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 25040.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4942.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 04 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_04\n",
      "Unique object shapes found for fold 04 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_04\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 05 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23120.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5270.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 05 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_05\n",
      "Unique object shapes found for fold 05 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_05\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 06 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24744.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5221.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 06 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_06\n",
      "Unique object shapes found for fold 06 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_06\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 07 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23104.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5219.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 07 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_07\n",
      "Unique object shapes found for fold 07 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_07\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 08 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23850.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5052.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 08 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_08\n",
      "Unique object shapes found for fold 08 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_08\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 09 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24131.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5085.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 09 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_09\n",
      "Unique object shapes found for fold 09 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_09\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 10 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22853.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5143.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 10 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_10\n",
      "Unique object shapes found for fold 10 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_10\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 11 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23679.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5272.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 11 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_11\n",
      "Unique object shapes found for fold 11 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_11\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 12 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22423.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4915.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 12 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_12\n",
      "Unique object shapes found for fold 12 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_12\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 13 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 22867.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4935.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 13 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_13\n",
      "Unique object shapes found for fold 13 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_13\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 14 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23402.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5136.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 14 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_14\n",
      "Unique object shapes found for fold 14 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_14\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 15 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23652.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5326.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 15 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_15\n",
      "Unique object shapes found for fold 15 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_15\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 16 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 23947.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5428.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 16 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_16\n",
      "Unique object shapes found for fold 16 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_16\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 17 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24473.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5401.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 17 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_17\n",
      "Unique object shapes found for fold 17 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_17\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 18 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24230.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5362.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 18 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_18\n",
      "Unique object shapes found for fold 18 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_18\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 19 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24427.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5341.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 19 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_19\n",
      "Unique object shapes found for fold 19 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_19\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 20 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24065.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5322.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 20 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_20\n",
      "Unique object shapes found for fold 20 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_20\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 21 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24707.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5452.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 21 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_21\n",
      "Unique object shapes found for fold 21 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_21\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 22 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24057.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 4431.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 22 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_22\n",
      "Unique object shapes found for fold 22 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_22\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 23 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24532.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5408.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 23 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_23\n",
      "Unique object shapes found for fold 23 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_23\n",
      "\n",
      "=== FILE DISCOVERY ===\n",
      "Found 1146 pose files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy\n",
      "✅ All pose files have at least one matching object file.\n",
      "\n",
      "Generating fold 24 splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning object files in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 100%|██████████| 1146/1146 [00:00<00:00, 24521.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of object nodes in /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/data/npy: 4\n",
      "Using n_obj_max = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 5444.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique object shapes found for fold 24 train: {(48, 4, 3)}\n",
      "Train set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_24\n",
      "Unique object shapes found for fold 24 eval: {(48, 4, 3)}\n",
      "Eval set saved → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_24\n",
      "Saved fold class distribution summary → /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_summary_actual.json\n",
      "Camera file exists: False\n",
      "Using fold: /Users/alexeidelgado/Desktop/mpgcn-playground-scenes/workdir/fold_00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Train pipeline",
   "id": "16977d3207e58fca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:43.845889Z",
     "start_time": "2025-11-29T23:44:43.840783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mpgcn_yaml_path = \"./config/playground/mpgcn.yaml\"\n",
    "with open(mpgcn_yaml_path, \"r\") as f:\n",
    "    mpgcn_cfg = yaml.safe_load(f)\n",
    "\n",
    "args = to_ns(mpgcn_cfg)\n",
    "args.config_path = mpgcn_yaml_path\n",
    "print(\"Loaded MPGCN YAML config.\")\n",
    "\n",
    "# Set FOLD_ID for training\n",
    "FOLD_ID = 0 # change this 0 → 1 → 2 → ... → 24 for CV\n",
    "fold_dir = f\"./workdir/fold_{FOLD_ID:02d}\"\n",
    "\n",
    "args.work_dir = \"./workdir\"\n",
    "args.dataset_args.root_folder = fold_dir\n",
    "args.dataset_args.object_folder = fold_dir\n",
    "\n",
    "print(\"Root folder:\", args.dataset_args.root_folder)"
   ],
   "id": "59db3b24a559fbc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MPGCN YAML config.\n",
      "Root folder: ./workdir/fold_00\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:45.661410Z",
     "start_time": "2025-11-29T23:44:45.658283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels_path = os.path.join(fold_dir, \"train_label.pkl\")\n",
    "\n",
    "with open(train_labels_path, \"rb\") as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "labels_arr = np.array([l for l, _ in train_labels])\n",
    "observed_classes = int(labels_arr.max()) + 1\n",
    "\n",
    "print(\"Observed label classes:\", observed_classes)"
   ],
   "id": "bfe1e7a69055cc9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed label classes: 3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:46.917912Z",
     "start_time": "2025-11-29T23:44:46.915239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args.dataset_args.debug = False\n",
    "args.dataset_args.augment = True\n",
    "\n",
    "# Inject correct class count into model_args\n",
    "args.model_args.num_class = observed_classes\n",
    "\n",
    "print(\"Model will be built with num_class =\", args.model_args.num_class)"
   ],
   "id": "5e26386c1443939e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be built with num_class = 3\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:48.508905Z",
     "start_time": "2025-11-29T23:44:48.491436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feeders, data_shape, num_class, A, parts = create_dataset(\n",
    "    args.dataset,\n",
    "    **vars(args.dataset_args)\n",
    ")\n",
    "\n",
    "print(\"train samples:\", len(feeders[\"train\"]))\n",
    "print(\"eval samples:\", len(feeders[\"eval\"]))\n",
    "print(\"data shape:\", data_shape)\n",
    "print(\"num classes:\", num_class)\n",
    "print(\"Feeder output structure:\", len(feeders[\"train\"][0]), \"items\", \"(should be 4: data, label, name, area_id)\")\n",
    "print(\"Area IDs example:\", feeders[\"train\"].area_ids[:10])"
   ],
   "id": "4f6a981acd6edc87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 793\n",
      "eval samples: 293\n",
      "data shape: [4, 6, 48, 84, 1]\n",
      "num classes: 3\n",
      "Feeder output structure: 4 items (should be 4: data, label, name, area_id)\n",
      "Area IDs example: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:50.727981Z",
     "start_time": "2025-11-29T23:44:50.725183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_areas = np.unique(feeders[\"train\"].area_ids)\n",
    "print(\"Unique area IDs in TRAIN:\", unique_areas)"
   ],
   "id": "7ffd256a006eee71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique area IDs in TRAIN: [0 1]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:51.809581Z",
     "start_time": "2025-11-29T23:44:51.675816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert adjacency matrix\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "A_tensor = A_tensor.to(device)\n",
    "\n",
    "num_areas = getattr(feeders[\"train\"], \"area_ids\", None)\n",
    "if num_areas is not None:\n",
    "    num_areas = int(np.max(feeders[\"train\"].area_ids)) + 1\n",
    "else:\n",
    "    num_areas = args.model_args.get(\"num_areas\", 2)\n",
    "\n",
    "model = MPGCN(\n",
    "    data_shape=data_shape,\n",
    "    A=A_tensor,\n",
    "    parts=parts,\n",
    "    num_class=args.model_args.num_class,\n",
    "    num_areas=num_areas,\n",
    "    area_emb_dim=32,\n",
    "    use_att=args.model_args.use_att,\n",
    "    kernel_size=args.model_args.kernel_size,\n",
    "    dilation=args.model_args.dilation,\n",
    "    reduct_ratio=args.model_args.reduct_ratio\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model successfully built!\")\n",
    "print(\"Model camera embedding support enabled. num_areas =\", num_areas)"
   ],
   "id": "489a6dc1311908d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model successfully built!\n",
      "Model camera embedding support enabled. num_areas = 2\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:53.646571Z",
     "start_time": "2025-11-29T23:44:53.640818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample, label, clip, _ = feeders[\"train\"][0]\n",
    "\n",
    "x = torch.tensor(sample).float().unsqueeze(0)  # add batch dim\n",
    "y = torch.tensor([label])\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "print(\"Input tensor:\", x.shape)\n",
    "print(\"Label:\", y)"
   ],
   "id": "ef470fd23070470a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor: torch.Size([1, 4, 6, 48, 84, 1])\n",
      "Label: tensor([1])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:55.607988Z",
     "start_time": "2025-11-29T23:44:55.512817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "area_id = torch.tensor([feeders[\"train\"].area_ids[0]]).long().to(device)\n",
    "out_tuple = model(x, area_id)\n",
    "logits = out_tuple[0]   # MP-GCN returns (output, feature_maps)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ],
   "id": "7389dd4d0d301ca9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 3])\n",
      "Logits: tensor([[ 0.0085,  0.0153, -0.0705]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:57.386729Z",
     "start_time": "2025-11-29T23:44:56.831341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.9,\n",
    "    nesterov=True,\n",
    "    weight_decay=0.0002\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "9d9f551e64d2451f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:44:59.636295Z",
     "start_time": "2025-11-29T23:44:59.076538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = args.dataset_args.train_batch_size\n",
    "eval_batch_size = args.dataset_args.eval_batch_size\n",
    "\n",
    "train_labels = []\n",
    "for _, y, _, _ in feeders['train']:\n",
    "    train_labels.append(int(y))\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "class_counts = np.bincount(train_labels, minlength=observed_classes) + 1e-6\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = class_weights[train_labels]\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    feeders['train'],\n",
    "    batch_size=train_batch_size, \n",
    "    sampler=train_sampler,\n",
    "    num_workers=4 if torch.cuda.is_available() else 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    feeders['eval'],\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4 if torch.cuda.is_available() else 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"Created data loaders with train_batch_size={train_batch_size}, eval_batch_size={eval_batch_size}\")\n",
    "print(f\"Train samples: {len(feeders['train'])}, batches: {len(train_loader)}\")\n",
    "print(f\"Eval samples: {len(feeders['eval'])}, batches: {len(eval_loader)}\")"
   ],
   "id": "48ffd889eb864b5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data loaders with train_batch_size=16, eval_batch_size=16\n",
      "Train samples: 793, batches: 49\n",
      "Eval samples: 293, batches: 19\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T23:45:01.448557Z",
     "start_time": "2025-11-29T23:45:01.443227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from src.scheduler import create as create_scheduler\n",
    "\n",
    "# scheduler_args is a SimpleNamespace, get attribute dynamically\n",
    "scheduler_args = getattr(args.scheduler_args, args.lr_scheduler)\n",
    "scheduler_args_dict = vars(scheduler_args)\n",
    "\n",
    "max_epoch = scheduler_args_dict[\"max_epoch\"]\n",
    "warm_up = scheduler_args_dict[\"warm_up\"]\n",
    "\n",
    "print(f\"Using {args.lr_scheduler} scheduler with max_epoch={max_epoch}, warm_up={warm_up}\")\n",
    "\n",
    "lr_scheduler = create_scheduler(\n",
    "    args.lr_scheduler,\n",
    "    len(train_loader),\n",
    "    **scheduler_args_dict\n",
    ")\n",
    "\n",
    "eval_interval, lr_lambda = lr_scheduler.get_lambda()\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ],
   "id": "2045dfb430d0881d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine scheduler with max_epoch=65, warm_up=5\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:31:13.935492Z",
     "start_time": "2025-11-29T23:45:03.097868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Starting full model training...\")\n",
    "\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{max_epoch}\")\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for batch_idx, (data, target, name, area_id) in enumerate(train_loader):\n",
    "        data = data.float().to(device)\n",
    "        target = target.long().to(device)\n",
    "        area_id = area_id.long().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data, area_id)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "        global_step += 1\n",
    "\n",
    "        # Print progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f} | \"\n",
    "                  f\"Acc: {100.*correct/total:.2f}% ({correct}/{total}) | \"\n",
    "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    if (epoch+1) % eval_interval(epoch) == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        print(\"Evaluating...\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target, name, area_id) in enumerate(eval_loader):\n",
    "                data = data.float().to(device)\n",
    "                target = target.long().to(device)\n",
    "                area_id = area_id.long().to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output, _ = model(data, area_id)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "\n",
    "        val_loss /= len(eval_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            print(f\"New best model with accuracy: {best_acc:.2f}%\")\n",
    "            # Save model checkpoint (optional)\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch + 1,\n",
    "            #     'model_state_dict': model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #     'scheduler_state_dict': scheduler.state_dict(),\n",
    "            #     'best_acc': best_acc,\n",
    "            # }, f'./workdir/best_model.pth')\n",
    "\n",
    "print(f\"Training completed. Best accuracy: {best_acc:.2f}% at epoch {best_epoch}\")"
   ],
   "id": "7f0c66a57074a0d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full model training...\n",
      "\n",
      "Epoch 1/65\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexeidelgado/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/49 | Loss: 1.1037 | Acc: 50.00% (8/16) | LR: 0.000204\n",
      "Batch 10/49 | Loss: 1.2565 | Acc: 38.64% (68/176) | LR: 0.002245\n",
      "Batch 20/49 | Loss: 1.1611 | Acc: 35.71% (120/336) | LR: 0.004286\n",
      "Batch 30/49 | Loss: 1.5274 | Acc: 37.70% (187/496) | LR: 0.006327\n",
      "Batch 40/49 | Loss: 0.8895 | Acc: 38.41% (252/656) | LR: 0.008367\n",
      "Train Loss: 1.3054 | Train Acc: 38.39%\n",
      "\n",
      "Epoch 2/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 4.0014 | Acc: 18.75% (3/16) | LR: 0.010204\n",
      "Batch 10/49 | Loss: 1.4408 | Acc: 31.82% (56/176) | LR: 0.012245\n",
      "Batch 20/49 | Loss: 2.6359 | Acc: 35.12% (118/336) | LR: 0.014286\n",
      "Batch 30/49 | Loss: 1.0374 | Acc: 37.10% (184/496) | LR: 0.016327\n",
      "Batch 40/49 | Loss: 1.5359 | Acc: 37.96% (249/656) | LR: 0.018367\n",
      "Train Loss: 2.0084 | Train Acc: 39.29%\n",
      "\n",
      "Epoch 3/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.4461 | Acc: 31.25% (5/16) | LR: 0.020204\n",
      "Batch 10/49 | Loss: 1.5573 | Acc: 40.34% (71/176) | LR: 0.022245\n",
      "Batch 20/49 | Loss: 1.5269 | Acc: 42.86% (144/336) | LR: 0.024286\n",
      "Batch 30/49 | Loss: 0.7072 | Acc: 44.15% (219/496) | LR: 0.026327\n",
      "Batch 40/49 | Loss: 1.3260 | Acc: 44.82% (294/656) | LR: 0.028367\n",
      "Train Loss: 1.4677 | Train Acc: 45.28%\n",
      "\n",
      "Epoch 4/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.4332 | Acc: 50.00% (8/16) | LR: 0.030204\n",
      "Batch 10/49 | Loss: 1.4346 | Acc: 40.34% (71/176) | LR: 0.032245\n",
      "Batch 20/49 | Loss: 1.0692 | Acc: 43.45% (146/336) | LR: 0.034286\n",
      "Batch 30/49 | Loss: 1.1990 | Acc: 42.74% (212/496) | LR: 0.036327\n",
      "Batch 40/49 | Loss: 1.1346 | Acc: 44.66% (293/656) | LR: 0.038367\n",
      "Train Loss: 1.2782 | Train Acc: 44.01%\n",
      "\n",
      "Epoch 5/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9154 | Acc: 43.75% (7/16) | LR: 0.040204\n",
      "Batch 10/49 | Loss: 1.0468 | Acc: 44.32% (78/176) | LR: 0.042245\n",
      "Batch 20/49 | Loss: 1.4091 | Acc: 43.75% (147/336) | LR: 0.044286\n",
      "Batch 30/49 | Loss: 0.8786 | Acc: 44.15% (219/496) | LR: 0.046327\n",
      "Batch 40/49 | Loss: 1.0169 | Acc: 43.60% (286/656) | LR: 0.048367\n",
      "Train Loss: 1.1999 | Train Acc: 44.26%\n",
      "Evaluating...\n",
      "Val Loss: 1.1070 | Val Acc: 49.15%\n",
      "New best model with accuracy: 49.15%\n",
      "\n",
      "Epoch 6/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0326 | Acc: 62.50% (10/16) | LR: 0.050000\n",
      "Batch 10/49 | Loss: 1.0473 | Acc: 48.30% (85/176) | LR: 0.049998\n",
      "Batch 20/49 | Loss: 0.8994 | Acc: 50.00% (168/336) | LR: 0.049994\n",
      "Batch 30/49 | Loss: 0.9727 | Acc: 49.40% (245/496) | LR: 0.049986\n",
      "Batch 40/49 | Loss: 1.0530 | Acc: 50.30% (330/656) | LR: 0.049976\n",
      "Train Loss: 1.1161 | Train Acc: 50.13%\n",
      "\n",
      "Epoch 7/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.5444 | Acc: 25.00% (4/16) | LR: 0.049964\n",
      "Batch 10/49 | Loss: 1.0883 | Acc: 40.91% (72/176) | LR: 0.049949\n",
      "Batch 20/49 | Loss: 1.2019 | Acc: 40.77% (137/336) | LR: 0.049930\n",
      "Batch 30/49 | Loss: 1.2472 | Acc: 40.32% (200/496) | LR: 0.049909\n",
      "Batch 40/49 | Loss: 1.0751 | Acc: 42.07% (276/656) | LR: 0.049884\n",
      "Train Loss: 1.1857 | Train Acc: 42.60%\n",
      "\n",
      "Epoch 8/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0841 | Acc: 43.75% (7/16) | LR: 0.049860\n",
      "Batch 10/49 | Loss: 0.8851 | Acc: 51.70% (91/176) | LR: 0.049831\n",
      "Batch 20/49 | Loss: 0.9920 | Acc: 50.60% (170/336) | LR: 0.049798\n",
      "Batch 30/49 | Loss: 0.7502 | Acc: 51.01% (253/496) | LR: 0.049763\n",
      "Batch 40/49 | Loss: 0.9890 | Acc: 51.37% (337/656) | LR: 0.049725\n",
      "Train Loss: 1.0824 | Train Acc: 49.62%\n",
      "\n",
      "Epoch 9/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0005 | Acc: 37.50% (6/16) | LR: 0.049688\n",
      "Batch 10/49 | Loss: 0.9319 | Acc: 42.05% (74/176) | LR: 0.049645\n",
      "Batch 20/49 | Loss: 1.1981 | Acc: 46.43% (156/336) | LR: 0.049598\n",
      "Batch 30/49 | Loss: 1.0826 | Acc: 49.80% (247/496) | LR: 0.049549\n",
      "Batch 40/49 | Loss: 0.8853 | Acc: 48.48% (318/656) | LR: 0.049497\n",
      "Train Loss: 1.0363 | Train Acc: 48.47%\n",
      "\n",
      "Epoch 10/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.2768 | Acc: 31.25% (5/16) | LR: 0.049448\n",
      "Batch 10/49 | Loss: 0.9187 | Acc: 51.70% (91/176) | LR: 0.049391\n",
      "Batch 20/49 | Loss: 1.2310 | Acc: 50.30% (169/336) | LR: 0.049331\n",
      "Batch 30/49 | Loss: 0.9642 | Acc: 52.02% (258/496) | LR: 0.049268\n",
      "Batch 40/49 | Loss: 1.2840 | Acc: 51.22% (336/656) | LR: 0.049203\n",
      "Train Loss: 1.0192 | Train Acc: 50.89%\n",
      "Evaluating...\n",
      "Val Loss: 1.2951 | Val Acc: 50.17%\n",
      "New best model with accuracy: 50.17%\n",
      "\n",
      "Epoch 11/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.3645 | Acc: 37.50% (6/16) | LR: 0.049141\n",
      "Batch 10/49 | Loss: 1.1251 | Acc: 43.18% (76/176) | LR: 0.049070\n",
      "Batch 20/49 | Loss: 0.8618 | Acc: 47.92% (161/336) | LR: 0.048997\n",
      "Batch 30/49 | Loss: 0.9520 | Acc: 48.59% (241/496) | LR: 0.048921\n",
      "Batch 40/49 | Loss: 0.8172 | Acc: 48.48% (318/656) | LR: 0.048842\n",
      "Train Loss: 1.0452 | Train Acc: 49.23%\n",
      "\n",
      "Epoch 12/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9878 | Acc: 50.00% (8/16) | LR: 0.048768\n",
      "Batch 10/49 | Loss: 0.8255 | Acc: 49.43% (87/176) | LR: 0.048684\n",
      "Batch 20/49 | Loss: 0.9350 | Acc: 54.76% (184/336) | LR: 0.048597\n",
      "Batch 30/49 | Loss: 1.1778 | Acc: 50.20% (249/496) | LR: 0.048508\n",
      "Batch 40/49 | Loss: 0.7483 | Acc: 50.76% (333/656) | LR: 0.048415\n",
      "Train Loss: 1.0119 | Train Acc: 51.28%\n",
      "\n",
      "Epoch 13/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.3545 | Acc: 37.50% (6/16) | LR: 0.048330\n",
      "Batch 10/49 | Loss: 1.0131 | Acc: 55.11% (97/176) | LR: 0.048233\n",
      "Batch 20/49 | Loss: 0.7861 | Acc: 55.95% (188/336) | LR: 0.048133\n",
      "Batch 30/49 | Loss: 1.1291 | Acc: 52.82% (262/496) | LR: 0.048030\n",
      "Batch 40/49 | Loss: 0.7854 | Acc: 54.27% (356/656) | LR: 0.047925\n",
      "Train Loss: 0.9840 | Train Acc: 53.70%\n",
      "\n",
      "Epoch 14/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8376 | Acc: 50.00% (8/16) | LR: 0.047828\n",
      "Batch 10/49 | Loss: 0.9339 | Acc: 48.30% (85/176) | LR: 0.047718\n",
      "Batch 20/49 | Loss: 1.1834 | Acc: 47.02% (158/336) | LR: 0.047605\n",
      "Batch 30/49 | Loss: 0.7948 | Acc: 47.38% (235/496) | LR: 0.047489\n",
      "Batch 40/49 | Loss: 0.8683 | Acc: 49.85% (327/656) | LR: 0.047371\n",
      "Train Loss: 0.9876 | Train Acc: 50.89%\n",
      "\n",
      "Epoch 15/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0002 | Acc: 68.75% (11/16) | LR: 0.047263\n",
      "Batch 10/49 | Loss: 1.0202 | Acc: 51.14% (90/176) | LR: 0.047140\n",
      "Batch 20/49 | Loss: 0.8621 | Acc: 52.38% (176/336) | LR: 0.047015\n",
      "Batch 30/49 | Loss: 1.2858 | Acc: 51.41% (255/496) | LR: 0.046887\n",
      "Batch 40/49 | Loss: 0.8911 | Acc: 53.05% (348/656) | LR: 0.046757\n",
      "Train Loss: 1.0150 | Train Acc: 52.81%\n",
      "Evaluating...\n",
      "Val Loss: 1.0636 | Val Acc: 51.54%\n",
      "New best model with accuracy: 51.54%\n",
      "\n",
      "Epoch 16/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8663 | Acc: 68.75% (11/16) | LR: 0.046637\n",
      "Batch 10/49 | Loss: 0.9612 | Acc: 55.11% (97/176) | LR: 0.046502\n",
      "Batch 20/49 | Loss: 0.9221 | Acc: 55.95% (188/336) | LR: 0.046365\n",
      "Batch 30/49 | Loss: 1.0889 | Acc: 56.05% (278/496) | LR: 0.046225\n",
      "Batch 40/49 | Loss: 1.1696 | Acc: 54.12% (355/656) | LR: 0.046082\n",
      "Train Loss: 0.9584 | Train Acc: 54.72%\n",
      "\n",
      "Epoch 17/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9773 | Acc: 37.50% (6/16) | LR: 0.045952\n",
      "Batch 10/49 | Loss: 0.9907 | Acc: 42.61% (75/176) | LR: 0.045805\n",
      "Batch 20/49 | Loss: 0.8550 | Acc: 48.51% (163/336) | LR: 0.045656\n",
      "Batch 30/49 | Loss: 0.8146 | Acc: 49.60% (246/496) | LR: 0.045504\n",
      "Batch 40/49 | Loss: 0.8233 | Acc: 50.46% (331/656) | LR: 0.045350\n",
      "Train Loss: 0.9915 | Train Acc: 50.89%\n",
      "\n",
      "Epoch 18/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7360 | Acc: 68.75% (11/16) | LR: 0.045210\n",
      "Batch 10/49 | Loss: 0.9547 | Acc: 52.27% (92/176) | LR: 0.045051\n",
      "Batch 20/49 | Loss: 0.8759 | Acc: 55.65% (187/336) | LR: 0.044891\n",
      "Batch 30/49 | Loss: 0.7389 | Acc: 54.23% (269/496) | LR: 0.044728\n",
      "Batch 40/49 | Loss: 1.0003 | Acc: 52.74% (346/656) | LR: 0.044562\n",
      "Train Loss: 0.9470 | Train Acc: 52.42%\n",
      "\n",
      "Epoch 19/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8812 | Acc: 50.00% (8/16) | LR: 0.044412\n",
      "Batch 10/49 | Loss: 0.8864 | Acc: 51.70% (91/176) | LR: 0.044242\n",
      "Batch 20/49 | Loss: 0.8442 | Acc: 55.95% (188/336) | LR: 0.044071\n",
      "Batch 30/49 | Loss: 0.7939 | Acc: 54.64% (271/496) | LR: 0.043897\n",
      "Batch 40/49 | Loss: 0.9483 | Acc: 54.27% (356/656) | LR: 0.043721\n",
      "Train Loss: 0.9319 | Train Acc: 55.99%\n",
      "\n",
      "Epoch 20/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7253 | Acc: 68.75% (11/16) | LR: 0.043561\n",
      "Batch 10/49 | Loss: 1.3150 | Acc: 53.98% (95/176) | LR: 0.043381\n",
      "Batch 20/49 | Loss: 0.9915 | Acc: 52.68% (177/336) | LR: 0.043199\n",
      "Batch 30/49 | Loss: 0.9256 | Acc: 51.21% (254/496) | LR: 0.043014\n",
      "Batch 40/49 | Loss: 1.0904 | Acc: 53.05% (348/656) | LR: 0.042828\n",
      "Train Loss: 0.9797 | Train Acc: 52.30%\n",
      "Evaluating...\n",
      "Val Loss: 1.1798 | Val Acc: 49.49%\n",
      "\n",
      "Epoch 21/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9891 | Acc: 56.25% (9/16) | LR: 0.042659\n",
      "Batch 10/49 | Loss: 0.8503 | Acc: 56.25% (99/176) | LR: 0.042469\n",
      "Batch 20/49 | Loss: 0.6708 | Acc: 56.25% (189/336) | LR: 0.042277\n",
      "Batch 30/49 | Loss: 0.8326 | Acc: 55.44% (275/496) | LR: 0.042082\n",
      "Batch 40/49 | Loss: 0.9436 | Acc: 54.57% (358/656) | LR: 0.041886\n",
      "Train Loss: 0.9343 | Train Acc: 54.21%\n",
      "\n",
      "Epoch 22/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8881 | Acc: 75.00% (12/16) | LR: 0.041708\n",
      "Batch 10/49 | Loss: 0.8487 | Acc: 60.23% (106/176) | LR: 0.041509\n",
      "Batch 20/49 | Loss: 1.0029 | Acc: 58.33% (196/336) | LR: 0.041307\n",
      "Batch 30/49 | Loss: 0.9023 | Acc: 57.86% (287/496) | LR: 0.041104\n",
      "Batch 40/49 | Loss: 0.8368 | Acc: 56.40% (370/656) | LR: 0.040899\n",
      "Train Loss: 0.9254 | Train Acc: 56.51%\n",
      "\n",
      "Epoch 23/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8885 | Acc: 68.75% (11/16) | LR: 0.040712\n",
      "Batch 10/49 | Loss: 1.0050 | Acc: 56.25% (99/176) | LR: 0.040504\n",
      "Batch 20/49 | Loss: 0.8737 | Acc: 53.87% (181/336) | LR: 0.040293\n",
      "Batch 30/49 | Loss: 0.9871 | Acc: 57.26% (284/496) | LR: 0.040081\n",
      "Batch 40/49 | Loss: 0.7900 | Acc: 55.64% (365/656) | LR: 0.039867\n",
      "Train Loss: 0.9489 | Train Acc: 55.10%\n",
      "\n",
      "Epoch 24/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9858 | Acc: 37.50% (6/16) | LR: 0.039673\n",
      "Batch 10/49 | Loss: 0.8433 | Acc: 58.52% (103/176) | LR: 0.039456\n",
      "Batch 20/49 | Loss: 0.7507 | Acc: 57.14% (192/336) | LR: 0.039237\n",
      "Batch 30/49 | Loss: 0.7689 | Acc: 58.06% (288/496) | LR: 0.039017\n",
      "Batch 40/49 | Loss: 0.7456 | Acc: 59.60% (391/656) | LR: 0.038795\n",
      "Train Loss: 0.9186 | Train Acc: 58.55%\n",
      "\n",
      "Epoch 25/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8320 | Acc: 62.50% (10/16) | LR: 0.038594\n",
      "Batch 10/49 | Loss: 0.8654 | Acc: 56.82% (100/176) | LR: 0.038369\n",
      "Batch 20/49 | Loss: 0.7332 | Acc: 58.33% (196/336) | LR: 0.038142\n",
      "Batch 30/49 | Loss: 1.1127 | Acc: 58.67% (291/496) | LR: 0.037914\n",
      "Batch 40/49 | Loss: 1.0888 | Acc: 58.23% (382/656) | LR: 0.037685\n",
      "Train Loss: 0.9206 | Train Acc: 57.78%\n",
      "Evaluating...\n",
      "Val Loss: 1.0053 | Val Acc: 57.34%\n",
      "New best model with accuracy: 57.34%\n",
      "\n",
      "Epoch 26/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8951 | Acc: 56.25% (9/16) | LR: 0.037477\n",
      "Batch 10/49 | Loss: 0.8912 | Acc: 56.25% (99/176) | LR: 0.037245\n",
      "Batch 20/49 | Loss: 0.8195 | Acc: 57.14% (192/336) | LR: 0.037011\n",
      "Batch 30/49 | Loss: 0.6843 | Acc: 57.06% (283/496) | LR: 0.036776\n",
      "Batch 40/49 | Loss: 0.7227 | Acc: 58.84% (386/656) | LR: 0.036540\n",
      "Train Loss: 0.8855 | Train Acc: 59.06%\n",
      "\n",
      "Epoch 27/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8844 | Acc: 62.50% (10/16) | LR: 0.036326\n",
      "Batch 10/49 | Loss: 0.9109 | Acc: 60.80% (107/176) | LR: 0.036087\n",
      "Batch 20/49 | Loss: 0.8502 | Acc: 62.80% (211/336) | LR: 0.035847\n",
      "Batch 30/49 | Loss: 0.6848 | Acc: 59.88% (297/496) | LR: 0.035606\n",
      "Batch 40/49 | Loss: 0.7525 | Acc: 57.77% (379/656) | LR: 0.035363\n",
      "Train Loss: 0.8600 | Train Acc: 58.29%\n",
      "\n",
      "Epoch 28/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7765 | Acc: 75.00% (12/16) | LR: 0.035144\n",
      "Batch 10/49 | Loss: 1.2162 | Acc: 63.07% (111/176) | LR: 0.034899\n",
      "Batch 20/49 | Loss: 0.7869 | Acc: 62.80% (211/336) | LR: 0.034653\n",
      "Batch 30/49 | Loss: 1.0544 | Acc: 61.69% (306/496) | LR: 0.034406\n",
      "Batch 40/49 | Loss: 0.8381 | Acc: 60.82% (399/656) | LR: 0.034158\n",
      "Train Loss: 0.8815 | Train Acc: 59.57%\n",
      "\n",
      "Epoch 29/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0903 | Acc: 50.00% (8/16) | LR: 0.033934\n",
      "Batch 10/49 | Loss: 0.9944 | Acc: 55.68% (98/176) | LR: 0.033684\n",
      "Batch 20/49 | Loss: 0.8072 | Acc: 58.04% (195/336) | LR: 0.033433\n",
      "Batch 30/49 | Loss: 1.1940 | Acc: 59.68% (296/496) | LR: 0.033181\n",
      "Batch 40/49 | Loss: 0.8336 | Acc: 59.45% (390/656) | LR: 0.032928\n",
      "Train Loss: 0.8634 | Train Acc: 59.69%\n",
      "\n",
      "Epoch 30/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0176 | Acc: 56.25% (9/16) | LR: 0.032700\n",
      "Batch 10/49 | Loss: 0.7678 | Acc: 51.70% (91/176) | LR: 0.032445\n",
      "Batch 20/49 | Loss: 0.8994 | Acc: 56.85% (191/336) | LR: 0.032190\n",
      "Batch 30/49 | Loss: 0.7122 | Acc: 58.67% (291/496) | LR: 0.031934\n",
      "Batch 40/49 | Loss: 0.9850 | Acc: 59.30% (389/656) | LR: 0.031677\n",
      "Train Loss: 0.8784 | Train Acc: 59.31%\n",
      "Evaluating...\n",
      "Val Loss: 1.1776 | Val Acc: 55.63%\n",
      "\n",
      "Epoch 31/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7946 | Acc: 68.75% (11/16) | LR: 0.031445\n",
      "Batch 10/49 | Loss: 0.6376 | Acc: 62.50% (110/176) | LR: 0.031186\n",
      "Batch 20/49 | Loss: 1.1683 | Acc: 58.63% (197/336) | LR: 0.030927\n",
      "Batch 30/49 | Loss: 1.0558 | Acc: 59.68% (296/496) | LR: 0.030667\n",
      "Batch 40/49 | Loss: 0.9437 | Acc: 58.99% (387/656) | LR: 0.030407\n",
      "Train Loss: 0.8583 | Train Acc: 58.42%\n",
      "\n",
      "Epoch 32/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7195 | Acc: 75.00% (12/16) | LR: 0.030172\n",
      "Batch 10/49 | Loss: 0.8239 | Acc: 59.66% (105/176) | LR: 0.029910\n",
      "Batch 20/49 | Loss: 0.7308 | Acc: 63.39% (213/336) | LR: 0.029648\n",
      "Batch 30/49 | Loss: 0.7528 | Acc: 64.31% (319/496) | LR: 0.029385\n",
      "Batch 40/49 | Loss: 0.8051 | Acc: 62.35% (409/656) | LR: 0.029122\n",
      "Train Loss: 0.8543 | Train Acc: 60.46%\n",
      "\n",
      "Epoch 33/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6138 | Acc: 81.25% (13/16) | LR: 0.028884\n",
      "Batch 10/49 | Loss: 1.0762 | Acc: 62.50% (110/176) | LR: 0.028620\n",
      "Batch 20/49 | Loss: 0.9291 | Acc: 58.63% (197/336) | LR: 0.028356\n",
      "Batch 30/49 | Loss: 1.0641 | Acc: 58.47% (290/496) | LR: 0.028091\n",
      "Batch 40/49 | Loss: 0.8349 | Acc: 58.23% (382/656) | LR: 0.027826\n",
      "Train Loss: 0.8599 | Train Acc: 58.16%\n",
      "\n",
      "Epoch 34/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8032 | Acc: 68.75% (11/16) | LR: 0.027587\n",
      "Batch 10/49 | Loss: 0.9926 | Acc: 58.52% (103/176) | LR: 0.027321\n",
      "Batch 20/49 | Loss: 0.7936 | Acc: 61.61% (207/336) | LR: 0.027055\n",
      "Batch 30/49 | Loss: 0.6872 | Acc: 61.09% (303/496) | LR: 0.026788\n",
      "Batch 40/49 | Loss: 0.9431 | Acc: 62.65% (411/656) | LR: 0.026522\n",
      "Train Loss: 0.8139 | Train Acc: 63.01%\n",
      "\n",
      "Epoch 35/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7835 | Acc: 62.50% (10/16) | LR: 0.026282\n",
      "Batch 10/49 | Loss: 0.7779 | Acc: 63.07% (111/176) | LR: 0.026015\n",
      "Batch 20/49 | Loss: 0.6382 | Acc: 61.61% (207/336) | LR: 0.025748\n",
      "Batch 30/49 | Loss: 0.8494 | Acc: 62.70% (311/496) | LR: 0.025481\n",
      "Batch 40/49 | Loss: 0.7102 | Acc: 61.43% (403/656) | LR: 0.025214\n",
      "Train Loss: 0.8324 | Train Acc: 61.35%\n",
      "Evaluating...\n",
      "Val Loss: 1.1432 | Val Acc: 57.68%\n",
      "New best model with accuracy: 57.68%\n",
      "\n",
      "Epoch 36/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.0708 | Acc: 37.50% (6/16) | LR: 0.024973\n",
      "Batch 10/49 | Loss: 0.7064 | Acc: 60.23% (106/176) | LR: 0.024706\n",
      "Batch 20/49 | Loss: 0.7275 | Acc: 61.01% (205/336) | LR: 0.024439\n",
      "Batch 30/49 | Loss: 0.8049 | Acc: 62.30% (309/496) | LR: 0.024172\n",
      "Batch 40/49 | Loss: 0.6995 | Acc: 62.50% (410/656) | LR: 0.023905\n",
      "Train Loss: 0.8148 | Train Acc: 62.88%\n",
      "\n",
      "Epoch 37/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.9698 | Acc: 56.25% (9/16) | LR: 0.023665\n",
      "Batch 10/49 | Loss: 0.5804 | Acc: 63.64% (112/176) | LR: 0.023398\n",
      "Batch 20/49 | Loss: 0.6266 | Acc: 66.37% (223/336) | LR: 0.023132\n",
      "Batch 30/49 | Loss: 1.1285 | Acc: 64.52% (320/496) | LR: 0.022865\n",
      "Batch 40/49 | Loss: 0.6339 | Acc: 63.72% (418/656) | LR: 0.022599\n",
      "Train Loss: 0.8220 | Train Acc: 63.01%\n",
      "\n",
      "Epoch 38/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7904 | Acc: 56.25% (9/16) | LR: 0.022360\n",
      "Batch 10/49 | Loss: 0.5197 | Acc: 63.64% (112/176) | LR: 0.022095\n",
      "Batch 20/49 | Loss: 0.7185 | Acc: 62.20% (209/336) | LR: 0.021830\n",
      "Batch 30/49 | Loss: 0.8052 | Acc: 61.90% (307/496) | LR: 0.021565\n",
      "Batch 40/49 | Loss: 0.6558 | Acc: 62.35% (409/656) | LR: 0.021300\n",
      "Train Loss: 0.7862 | Train Acc: 62.88%\n",
      "\n",
      "Epoch 39/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8307 | Acc: 50.00% (8/16) | LR: 0.021063\n",
      "Batch 10/49 | Loss: 0.5241 | Acc: 65.34% (115/176) | LR: 0.020799\n",
      "Batch 20/49 | Loss: 1.2526 | Acc: 63.39% (213/336) | LR: 0.020536\n",
      "Batch 30/49 | Loss: 0.5585 | Acc: 65.32% (324/496) | LR: 0.020273\n",
      "Batch 40/49 | Loss: 0.7703 | Acc: 66.46% (436/656) | LR: 0.020011\n",
      "Train Loss: 0.7651 | Train Acc: 66.20%\n",
      "\n",
      "Epoch 40/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6851 | Acc: 62.50% (10/16) | LR: 0.019776\n",
      "Batch 10/49 | Loss: 1.1246 | Acc: 56.82% (100/176) | LR: 0.019515\n",
      "Batch 20/49 | Loss: 1.0445 | Acc: 58.04% (195/336) | LR: 0.019255\n",
      "Batch 30/49 | Loss: 0.6092 | Acc: 59.07% (293/496) | LR: 0.018995\n",
      "Batch 40/49 | Loss: 0.6838 | Acc: 61.43% (403/656) | LR: 0.018736\n",
      "Train Loss: 0.8156 | Train Acc: 61.86%\n",
      "Evaluating...\n",
      "Val Loss: 1.0373 | Val Acc: 58.36%\n",
      "New best model with accuracy: 58.36%\n",
      "\n",
      "Epoch 41/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8945 | Acc: 81.25% (13/16) | LR: 0.018504\n",
      "Batch 10/49 | Loss: 0.4971 | Acc: 71.02% (125/176) | LR: 0.018246\n",
      "Batch 20/49 | Loss: 0.8967 | Acc: 66.37% (223/336) | LR: 0.017989\n",
      "Batch 30/49 | Loss: 1.0835 | Acc: 64.72% (321/496) | LR: 0.017733\n",
      "Batch 40/49 | Loss: 0.4788 | Acc: 65.55% (430/656) | LR: 0.017478\n",
      "Train Loss: 0.7474 | Train Acc: 65.82%\n",
      "\n",
      "Epoch 42/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8222 | Acc: 56.25% (9/16) | LR: 0.017249\n",
      "Batch 10/49 | Loss: 0.7299 | Acc: 68.75% (121/176) | LR: 0.016996\n",
      "Batch 20/49 | Loss: 0.5239 | Acc: 67.86% (228/336) | LR: 0.016743\n",
      "Batch 30/49 | Loss: 0.6487 | Acc: 67.34% (334/496) | LR: 0.016491\n",
      "Batch 40/49 | Loss: 0.7242 | Acc: 67.68% (444/656) | LR: 0.016241\n",
      "Train Loss: 0.7250 | Train Acc: 68.11%\n",
      "\n",
      "Epoch 43/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7807 | Acc: 56.25% (9/16) | LR: 0.016016\n",
      "Batch 10/49 | Loss: 0.6072 | Acc: 65.34% (115/176) | LR: 0.015767\n",
      "Batch 20/49 | Loss: 0.9129 | Acc: 64.88% (218/336) | LR: 0.015519\n",
      "Batch 30/49 | Loss: 0.5801 | Acc: 66.94% (332/496) | LR: 0.015273\n",
      "Batch 40/49 | Loss: 1.0984 | Acc: 66.31% (435/656) | LR: 0.015027\n",
      "Train Loss: 0.7499 | Train Acc: 66.58%\n",
      "\n",
      "Epoch 44/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7342 | Acc: 68.75% (11/16) | LR: 0.014807\n",
      "Batch 10/49 | Loss: 0.7097 | Acc: 66.48% (117/176) | LR: 0.014564\n",
      "Batch 20/49 | Loss: 0.7832 | Acc: 69.35% (233/336) | LR: 0.014322\n",
      "Batch 30/49 | Loss: 0.7448 | Acc: 69.56% (345/496) | LR: 0.014081\n",
      "Batch 40/49 | Loss: 0.8523 | Acc: 68.60% (450/656) | LR: 0.013841\n",
      "Train Loss: 0.7165 | Train Acc: 67.86%\n",
      "\n",
      "Epoch 45/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6997 | Acc: 56.25% (9/16) | LR: 0.013626\n",
      "Batch 10/49 | Loss: 0.6962 | Acc: 67.05% (118/176) | LR: 0.013389\n",
      "Batch 20/49 | Loss: 0.8544 | Acc: 65.48% (220/336) | LR: 0.013153\n",
      "Batch 30/49 | Loss: 0.7251 | Acc: 66.33% (329/496) | LR: 0.012919\n",
      "Batch 40/49 | Loss: 0.8769 | Acc: 65.40% (429/656) | LR: 0.012686\n",
      "Train Loss: 0.7294 | Train Acc: 66.33%\n",
      "Evaluating...\n",
      "Val Loss: 1.1468 | Val Acc: 57.34%\n",
      "\n",
      "Epoch 46/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 1.1552 | Acc: 31.25% (5/16) | LR: 0.012477\n",
      "Batch 10/49 | Loss: 0.5839 | Acc: 69.32% (122/176) | LR: 0.012246\n",
      "Batch 20/49 | Loss: 0.6694 | Acc: 69.35% (233/336) | LR: 0.012017\n",
      "Batch 30/49 | Loss: 0.5733 | Acc: 68.15% (338/496) | LR: 0.011790\n",
      "Batch 40/49 | Loss: 0.6485 | Acc: 66.77% (438/656) | LR: 0.011564\n",
      "Train Loss: 0.6869 | Train Acc: 68.11%\n",
      "\n",
      "Epoch 47/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6720 | Acc: 75.00% (12/16) | LR: 0.011362\n",
      "Batch 10/49 | Loss: 0.4607 | Acc: 64.20% (113/176) | LR: 0.011139\n",
      "Batch 20/49 | Loss: 0.8206 | Acc: 66.37% (223/336) | LR: 0.010917\n",
      "Batch 30/49 | Loss: 0.6135 | Acc: 68.15% (338/496) | LR: 0.010697\n",
      "Batch 40/49 | Loss: 0.5021 | Acc: 69.36% (455/656) | LR: 0.010479\n",
      "Train Loss: 0.7031 | Train Acc: 70.03%\n",
      "\n",
      "Epoch 48/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.8043 | Acc: 62.50% (10/16) | LR: 0.010284\n",
      "Batch 10/49 | Loss: 0.6904 | Acc: 65.91% (116/176) | LR: 0.010069\n",
      "Batch 20/49 | Loss: 0.6096 | Acc: 69.05% (232/336) | LR: 0.009855\n",
      "Batch 30/49 | Loss: 0.6939 | Acc: 68.15% (338/496) | LR: 0.009644\n",
      "Batch 40/49 | Loss: 0.6255 | Acc: 69.97% (459/656) | LR: 0.009434\n",
      "Train Loss: 0.6910 | Train Acc: 70.41%\n",
      "\n",
      "Epoch 49/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.4429 | Acc: 93.75% (15/16) | LR: 0.009246\n",
      "Batch 10/49 | Loss: 0.6153 | Acc: 73.30% (129/176) | LR: 0.009040\n",
      "Batch 20/49 | Loss: 0.6069 | Acc: 70.54% (237/336) | LR: 0.008835\n",
      "Batch 30/49 | Loss: 0.9717 | Acc: 70.56% (350/496) | LR: 0.008632\n",
      "Batch 40/49 | Loss: 0.5973 | Acc: 70.27% (461/656) | LR: 0.008431\n",
      "Train Loss: 0.7123 | Train Acc: 69.77%\n",
      "\n",
      "Epoch 50/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.5572 | Acc: 68.75% (11/16) | LR: 0.008252\n",
      "Batch 10/49 | Loss: 0.8610 | Acc: 73.30% (129/176) | LR: 0.008055\n",
      "Batch 20/49 | Loss: 0.5898 | Acc: 70.54% (237/336) | LR: 0.007859\n",
      "Batch 30/49 | Loss: 0.4940 | Acc: 69.15% (343/496) | LR: 0.007666\n",
      "Batch 40/49 | Loss: 0.7092 | Acc: 70.12% (460/656) | LR: 0.007474\n",
      "Train Loss: 0.6551 | Train Acc: 69.90%\n",
      "Evaluating...\n",
      "Val Loss: 1.1738 | Val Acc: 57.00%\n",
      "\n",
      "Epoch 51/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6439 | Acc: 62.50% (10/16) | LR: 0.007303\n",
      "Batch 10/49 | Loss: 0.4494 | Acc: 71.59% (126/176) | LR: 0.007116\n",
      "Batch 20/49 | Loss: 0.7608 | Acc: 69.94% (235/336) | LR: 0.006930\n",
      "Batch 30/49 | Loss: 0.4172 | Acc: 70.56% (350/496) | LR: 0.006747\n",
      "Batch 40/49 | Loss: 0.5969 | Acc: 70.43% (462/656) | LR: 0.006565\n",
      "Train Loss: 0.6402 | Train Acc: 71.17%\n",
      "\n",
      "Epoch 52/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6810 | Acc: 62.50% (10/16) | LR: 0.006404\n",
      "Batch 10/49 | Loss: 0.5353 | Acc: 72.73% (128/176) | LR: 0.006226\n",
      "Batch 20/49 | Loss: 0.4310 | Acc: 69.64% (234/336) | LR: 0.006051\n",
      "Batch 30/49 | Loss: 0.3873 | Acc: 73.19% (363/496) | LR: 0.005878\n",
      "Batch 40/49 | Loss: 0.7311 | Acc: 71.65% (470/656) | LR: 0.005707\n",
      "Train Loss: 0.6315 | Train Acc: 72.07%\n",
      "\n",
      "Epoch 53/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6146 | Acc: 62.50% (10/16) | LR: 0.005555\n",
      "Batch 10/49 | Loss: 0.6413 | Acc: 72.73% (128/176) | LR: 0.005388\n",
      "Batch 20/49 | Loss: 0.9102 | Acc: 71.43% (240/336) | LR: 0.005223\n",
      "Batch 30/49 | Loss: 0.6201 | Acc: 72.58% (360/496) | LR: 0.005061\n",
      "Batch 40/49 | Loss: 0.4516 | Acc: 72.26% (474/656) | LR: 0.004901\n",
      "Train Loss: 0.6103 | Train Acc: 72.70%\n",
      "\n",
      "Epoch 54/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6940 | Acc: 68.75% (11/16) | LR: 0.004759\n",
      "Batch 10/49 | Loss: 0.5233 | Acc: 71.02% (125/176) | LR: 0.004603\n",
      "Batch 20/49 | Loss: 0.5497 | Acc: 71.73% (241/336) | LR: 0.004450\n",
      "Batch 30/49 | Loss: 0.8896 | Acc: 71.57% (355/496) | LR: 0.004299\n",
      "Batch 40/49 | Loss: 0.5794 | Acc: 71.04% (466/656) | LR: 0.004150\n",
      "Train Loss: 0.6255 | Train Acc: 73.09%\n",
      "\n",
      "Epoch 55/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6501 | Acc: 75.00% (12/16) | LR: 0.004019\n",
      "Batch 10/49 | Loss: 0.4691 | Acc: 77.84% (137/176) | LR: 0.003875\n",
      "Batch 20/49 | Loss: 0.6442 | Acc: 75.89% (255/336) | LR: 0.003733\n",
      "Batch 30/49 | Loss: 0.4312 | Acc: 74.80% (371/496) | LR: 0.003594\n",
      "Batch 40/49 | Loss: 0.5352 | Acc: 77.29% (507/656) | LR: 0.003457\n",
      "Train Loss: 0.5513 | Train Acc: 77.55%\n",
      "Evaluating...\n",
      "Val Loss: 1.2035 | Val Acc: 59.39%\n",
      "New best model with accuracy: 59.39%\n",
      "\n",
      "Epoch 56/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6055 | Acc: 68.75% (11/16) | LR: 0.003336\n",
      "Batch 10/49 | Loss: 0.7557 | Acc: 70.45% (124/176) | LR: 0.003204\n",
      "Batch 20/49 | Loss: 0.4276 | Acc: 74.11% (249/336) | LR: 0.003074\n",
      "Batch 30/49 | Loss: 0.5246 | Acc: 72.98% (362/496) | LR: 0.002947\n",
      "Batch 40/49 | Loss: 0.5720 | Acc: 74.39% (488/656) | LR: 0.002823\n",
      "Train Loss: 0.5759 | Train Acc: 74.36%\n",
      "Evaluating...\n",
      "Val Loss: 1.2669 | Val Acc: 56.66%\n",
      "\n",
      "Epoch 57/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.3045 | Acc: 93.75% (15/16) | LR: 0.002713\n",
      "Batch 10/49 | Loss: 0.5541 | Acc: 78.41% (138/176) | LR: 0.002593\n",
      "Batch 20/49 | Loss: 0.5205 | Acc: 76.19% (256/336) | LR: 0.002476\n",
      "Batch 30/49 | Loss: 0.7811 | Acc: 73.59% (365/496) | LR: 0.002361\n",
      "Batch 40/49 | Loss: 0.6277 | Acc: 72.71% (477/656) | LR: 0.002249\n",
      "Train Loss: 0.5944 | Train Acc: 72.96%\n",
      "Evaluating...\n",
      "Val Loss: 1.1929 | Val Acc: 60.41%\n",
      "New best model with accuracy: 60.41%\n",
      "\n",
      "Epoch 58/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.4428 | Acc: 93.75% (15/16) | LR: 0.002151\n",
      "Batch 10/49 | Loss: 0.8435 | Acc: 75.57% (133/176) | LR: 0.002043\n",
      "Batch 20/49 | Loss: 0.4680 | Acc: 76.79% (258/336) | LR: 0.001939\n",
      "Batch 30/49 | Loss: 0.6193 | Acc: 75.81% (376/496) | LR: 0.001837\n",
      "Batch 40/49 | Loss: 0.4438 | Acc: 75.15% (493/656) | LR: 0.001738\n",
      "Train Loss: 0.5868 | Train Acc: 75.00%\n",
      "Evaluating...\n",
      "Val Loss: 1.1527 | Val Acc: 59.04%\n",
      "\n",
      "Epoch 59/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6762 | Acc: 68.75% (11/16) | LR: 0.001651\n",
      "Batch 10/49 | Loss: 0.6991 | Acc: 71.59% (126/176) | LR: 0.001557\n",
      "Batch 20/49 | Loss: 0.5461 | Acc: 71.73% (241/336) | LR: 0.001465\n",
      "Batch 30/49 | Loss: 0.6627 | Acc: 72.98% (362/496) | LR: 0.001377\n",
      "Batch 40/49 | Loss: 0.4980 | Acc: 74.54% (489/656) | LR: 0.001290\n",
      "Train Loss: 0.6117 | Train Acc: 72.96%\n",
      "Evaluating...\n",
      "Val Loss: 1.1618 | Val Acc: 61.43%\n",
      "New best model with accuracy: 61.43%\n",
      "\n",
      "Epoch 60/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.3594 | Acc: 87.50% (14/16) | LR: 0.001215\n",
      "Batch 10/49 | Loss: 0.4679 | Acc: 77.27% (136/176) | LR: 0.001134\n",
      "Batch 20/49 | Loss: 0.4361 | Acc: 75.30% (253/336) | LR: 0.001056\n",
      "Batch 30/49 | Loss: 0.6087 | Acc: 73.59% (365/496) | LR: 0.000981\n",
      "Batch 40/49 | Loss: 0.4939 | Acc: 73.63% (483/656) | LR: 0.000908\n",
      "Train Loss: 0.5894 | Train Acc: 74.11%\n",
      "Evaluating...\n",
      "Val Loss: 1.1995 | Val Acc: 61.43%\n",
      "\n",
      "Epoch 61/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.4955 | Acc: 75.00% (12/16) | LR: 0.000845\n",
      "Batch 10/49 | Loss: 0.2336 | Acc: 76.70% (135/176) | LR: 0.000777\n",
      "Batch 20/49 | Loss: 0.7048 | Acc: 74.70% (251/336) | LR: 0.000713\n",
      "Batch 30/49 | Loss: 0.9686 | Acc: 72.58% (360/496) | LR: 0.000651\n",
      "Batch 40/49 | Loss: 0.7387 | Acc: 72.71% (477/656) | LR: 0.000592\n",
      "Train Loss: 0.5864 | Train Acc: 72.96%\n",
      "Evaluating...\n",
      "Val Loss: 1.2183 | Val Acc: 59.73%\n",
      "\n",
      "Epoch 62/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.4329 | Acc: 87.50% (14/16) | LR: 0.000541\n",
      "Batch 10/49 | Loss: 0.4036 | Acc: 77.27% (136/176) | LR: 0.000487\n",
      "Batch 20/49 | Loss: 0.6501 | Acc: 75.60% (254/336) | LR: 0.000436\n",
      "Batch 30/49 | Loss: 0.6258 | Acc: 74.80% (371/496) | LR: 0.000388\n",
      "Batch 40/49 | Loss: 0.7559 | Acc: 75.61% (496/656) | LR: 0.000342\n",
      "Train Loss: 0.5549 | Train Acc: 75.89%\n",
      "Evaluating...\n",
      "Val Loss: 1.2245 | Val Acc: 59.04%\n",
      "\n",
      "Epoch 63/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.6393 | Acc: 75.00% (12/16) | LR: 0.000304\n",
      "Batch 10/49 | Loss: 0.4254 | Acc: 78.41% (138/176) | LR: 0.000264\n",
      "Batch 20/49 | Loss: 0.6845 | Acc: 77.08% (259/336) | LR: 0.000226\n",
      "Batch 30/49 | Loss: 0.7306 | Acc: 75.60% (375/496) | LR: 0.000192\n",
      "Batch 40/49 | Loss: 0.5772 | Acc: 76.07% (499/656) | LR: 0.000160\n",
      "Train Loss: 0.5475 | Train Acc: 77.04%\n",
      "Evaluating...\n",
      "Val Loss: 1.1591 | Val Acc: 59.39%\n",
      "\n",
      "Epoch 64/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.3416 | Acc: 93.75% (15/16) | LR: 0.000134\n",
      "Batch 10/49 | Loss: 0.4624 | Acc: 75.57% (133/176) | LR: 0.000108\n",
      "Batch 20/49 | Loss: 0.4609 | Acc: 73.21% (246/336) | LR: 0.000085\n",
      "Batch 30/49 | Loss: 0.6389 | Acc: 73.79% (366/496) | LR: 0.000064\n",
      "Batch 40/49 | Loss: 0.6275 | Acc: 73.78% (484/656) | LR: 0.000046\n",
      "Train Loss: 0.5803 | Train Acc: 74.49%\n",
      "Evaluating...\n",
      "Val Loss: 1.2680 | Val Acc: 57.68%\n",
      "\n",
      "Epoch 65/65\n",
      "Training...\n",
      "Batch 0/49 | Loss: 0.7819 | Acc: 56.25% (9/16) | LR: 0.000033\n",
      "Batch 10/49 | Loss: 0.5191 | Acc: 69.89% (123/176) | LR: 0.000021\n",
      "Batch 20/49 | Loss: 0.5618 | Acc: 71.13% (239/336) | LR: 0.000011\n",
      "Batch 30/49 | Loss: 0.6380 | Acc: 71.77% (356/496) | LR: 0.000005\n",
      "Batch 40/49 | Loss: 0.4810 | Acc: 71.95% (472/656) | LR: 0.000001\n",
      "Train Loss: 0.5877 | Train Acc: 73.09%\n",
      "Evaluating...\n",
      "Val Loss: 1.2170 | Val Acc: 59.39%\n",
      "Training completed. Best accuracy: 61.43% at epoch 59\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:11:54.841752Z",
     "start_time": "2025-12-02T01:10:51.003889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target, name, area_id in eval_loader:\n",
    "        # keep only samples where target ∈ {0,1,2}\n",
    "        mask = target < 3\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        data = data[mask].float().to(device)\n",
    "        target = target[mask].long().to(device)\n",
    "        area_id = area_id[mask].long().to(device)\n",
    "\n",
    "        out,_ = model(data, area_id)\n",
    "        pred = out.argmax(1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(pred)\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "print(classification_report(\n",
    "    all_targets, all_preds,\n",
    "    target_names=[\"Transit\", \"Social_People\", \"Play_Object_Normal\"]\n",
    "))"
   ],
   "id": "bbeaafdf226b7b43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Transit       0.76      0.65      0.70       182\n",
      "     Social_People       0.42      0.58      0.48        66\n",
      "Play_Object_Normal       0.37      0.38      0.37        45\n",
      "\n",
      "          accuracy                           0.59       293\n",
      "         macro avg       0.52      0.54      0.52       293\n",
      "      weighted avg       0.62      0.59      0.60       293\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:11:54.969192Z",
     "start_time": "2025-12-02T01:11:54.904982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ],
   "id": "f83bdc00ea23243d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:45:01.888632Z",
     "start_time": "2025-11-27T23:44:12.721164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Load eval labels\n",
    "with open(os.path.join(args.dataset_args.root_folder, \"eval_label.pkl\"), \"rb\") as f:\n",
    "    eval_labels = pickle.load(f)\n",
    "\n",
    "# Extract clip names\n",
    "clip_names_eval = [name for _, name in eval_labels]\n",
    "\n",
    "# Area mapping must match your feeder and reader\n",
    "AREA_REGEX = {\n",
    "    \"hundido\": r\"hundidocam\\d+\",\n",
    "    \"columpios\": r\"(columpios[_]?cam\\d+|columpios_tierra)\"\n",
    "}\n",
    "\n",
    "def get_area(name):\n",
    "    import re\n",
    "    if re.search(AREA_REGEX[\"hundido\"], name):\n",
    "        return \"hundido\"\n",
    "    if re.search(AREA_REGEX[\"columpios\"], name):\n",
    "        return \"columpios\"\n",
    "    return \"unknown\"\n",
    "\n",
    "area_to_id = {\"hundido\": 0, \"columpios\": 1, \"unknown\": 2}\n",
    "\n",
    "for area_name, area_id in area_to_id.items():\n",
    "\n",
    "    # Find all clips in this area\n",
    "    indices = [i for i, name in enumerate(clip_names_eval)\n",
    "               if get_area(name) == area_name]\n",
    "\n",
    "    if not indices:\n",
    "        print(area_name, \"→ no samples in eval split\")\n",
    "        continue\n",
    "\n",
    "    subset = Subset(feeders[\"eval\"], indices)\n",
    "    loader = DataLoader(subset, batch_size=16)\n",
    "\n",
    "    preds, targets = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d, t, _, a in loader:\n",
    "            d = d.to(device).float()\n",
    "            a = a.to(device).long()\n",
    "            out, _ = model(d, a)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            targets.extend(t.numpy())\n",
    "\n",
    "    acc = np.mean(np.array(preds) == np.array(targets))\n",
    "    print(area_name, f\"accuracy = {acc:.3f}\")"
   ],
   "id": "c51f38fa010f57be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundido accuracy = 1.000\n",
      "columpios accuracy = 0.608\n",
      "unknown → no samples in eval split\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:50:03.695625Z",
     "start_time": "2025-11-27T23:49:56.909620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data, target, _, area_id = next(iter(eval_loader))\n",
    "data = data.float().to(device)\n",
    "area_id = area_id.long().to(device)\n",
    "out, feats = model(data, area_id)\n",
    "print(\"Feature shape:\", feats.shape)"
   ],
   "id": "93bc2f0520fb1a88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexeidelgado/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([8, 256, 12, 84, 1])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:08:26.961717Z",
     "start_time": "2025-11-28T00:08:04.010510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "all_feats = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target, _, area_id in eval_loader:\n",
    "        data = data.float().to(device)\n",
    "        area_id = area_id.long().to(device)\n",
    "\n",
    "        out, feats = model(data, area_id)\n",
    "\n",
    "        # Global Average Pooling: [B, 256, 12, 84, 1] → [B, 256]\n",
    "        feats = feats.mean(dim=(2, 3, 4))\n",
    "\n",
    "        all_feats.append(feats.cpu().numpy())\n",
    "        all_targets.append(target.numpy())\n",
    "\n",
    "X = np.concatenate(all_feats, axis=0)   # shape: (N, 256)\n",
    "y = np.concatenate(all_targets, axis=0)\n",
    "print(\"Final feature matrix:\", X.shape)"
   ],
   "id": "d662e9516d911f82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix: (284, 256)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:08:44.447010Z",
     "start_time": "2025-11-28T00:08:44.212100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca2 = pca.fit_transform(X)\n",
    "\n",
    "print(\"Explained variance:\", pca.explained_variance_ratio_)"
   ],
   "id": "5a536727b53787a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [0.4754481 0.1174148]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:08:51.060395Z",
     "start_time": "2025-11-28T00:08:50.986020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca3 = PCA(n_components=3)\n",
    "X_pca3 = pca3.fit_transform(X)\n",
    "\n",
    "print(pca3.explained_variance_ratio_)"
   ],
   "id": "926396b009f8e5ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4754481 0.1174148 0.1021516]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T17:48:07.586929Z",
     "start_time": "2025-11-28T00:08:55.329485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pool features\n",
    "X = np.concatenate(all_feats, axis=0)      # (293, 256)\n",
    "y = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "# PCA to 20 dims for speed\n",
    "from sklearn.decomposition import PCA\n",
    "pca20 = PCA(n_components=20)\n",
    "X20 = pca20.fit_transform(X)\n",
    "\n",
    "# CPU-friendly UMAP\n",
    "import umap\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.2,\n",
    "    metric='euclidean'\n",
    ")\n",
    "X_umap = umap_reducer.fit_transform(X20)\n",
    "\n",
    "# PCA-only 2D\n",
    "X_pca2 = PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "# t-SNE on 20 dims\n",
    "from sklearn.manifold import TSNE\n",
    "X_tsne = TSNE(n_components=2, perplexity=20).fit_transform(X20)"
   ],
   "id": "74d3bb04b0e14d39",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
